{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# 🚀 AI-Enhanced Risk Assessment Tool for Space Missions\n",
        "\n",
        "This notebook implements a comprehensive AI-powered risk assessment system specifically designed for space missions. The system uses machine learning to evaluate threats and assets based on multiple criteria and provides automated risk scoring.\n",
        "\n",
        "## Features:\n",
        "- **Multi-criteria risk assessment** with 7 threat criteria and 9 asset criteria\n",
        "- **Machine Learning models** for automated risk prediction\n",
        "- **Comprehensive threat catalog** with 57 different space-related threats\n",
        "- **Asset categorization** covering all space mission components\n",
        "- **Performance evaluation** and visualization tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# IMPORTS AND DEPENDENCIES\n",
        "# ====================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"🚀 AI Risk Assessment System - Dependencies Loaded\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "constants"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# RISK CRITERIA DEFINITIONS\n",
        "# ====================================================================\n",
        "\n",
        "def get_threat_criteria():\n",
        "    \"\"\"\n",
        "    Returns the threat assessment criteria.\n",
        "    \n",
        "    Returns:\n",
        "        dict: Dictionary containing 7 threat criteria (5 likelihood + 2 impact)\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"vulnerability_effectiveness\": \"Evaluates the effectiveness of vulnerability exploitation\",\n",
        "        \"mitigation_presence\": \"Evaluates the presence of security countermeasures\",\n",
        "        \"detection_probability\": \"Measures the probability of detecting malicious activities\",\n",
        "        \"access_complexity\": \"Evaluates the difficulty of access for an attacker\",\n",
        "        \"privilege_requirement\": \"Evaluates the level of privileges required\",\n",
        "        \"response_delay\": \"Measures the speed of incident response\",\n",
        "        \"resilience_impact\": \"Evaluates the impact on operational resilience\"\n",
        "    }\n",
        "\n",
        "def get_asset_criteria():\n",
        "    \"\"\"\n",
        "    Returns the asset assessment criteria.\n",
        "    \n",
        "    Returns:\n",
        "        dict: Dictionary containing 9 asset criteria (4 likelihood + 5 impact)\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"dependency\": \"Evaluates how critical the asset is for operations\",\n",
        "        \"penetration\": \"Evaluates the level of access obtainable through this asset\",\n",
        "        \"cyber_maturity\": \"Evaluates the maturity of cybersecurity governance\",\n",
        "        \"trust\": \"Evaluates the reliability of involved stakeholders\",\n",
        "        \"performance\": \"Measures the impact on operational performance\",\n",
        "        \"schedule\": \"Evaluates the impact on project timelines\",\n",
        "        \"costs\": \"Evaluates the financial impact\",\n",
        "        \"reputation\": \"Evaluates the reputational impact\",\n",
        "        \"recovery\": \"Measures time and effort for restoration\"\n",
        "    }\n",
        "\n",
        "def get_threat_catalog():\n",
        "    \"\"\"\n",
        "    Returns the comprehensive threat catalog for space missions.\n",
        "    \n",
        "    Returns:\n",
        "        list: List of 57 different threat types\n",
        "    \"\"\"\n",
        "    return [\n",
        "        \"Abuse of leaked data\",\n",
        "        \"Abuse / Falsification of right\",\n",
        "        \"Compromising confidentail information (data breaches): Exfiltration\",\n",
        "        \"Denial of Service (DoS)\",\n",
        "        \"Data modification\",\n",
        "        \"Electromagnetic interference\",\n",
        "        \"Firmware corruption\",\n",
        "        \"Identity Theft\",\n",
        "        \"Jamming\",\n",
        "        \"Malicious code/ software/activity: Cryptographic exploit\",\n",
        "        \"Malicious code/ software/activity: Malicious injection\",\n",
        "        \"Malicious code/ software/activity: Network exploit\",\n",
        "        \"Malicious code/ software/activity: Software and vulnerabilities' exploit\",\n",
        "        \"Manipulation of hardware and software: Zero Day exploit\",\n",
        "        \"Preventing services\",\n",
        "        \"Resource exhaustion\",\n",
        "        \"Seizure of control: Satellite bus\",\n",
        "        \"Social Engineering\",\n",
        "        \"Spoofing\",\n",
        "        \"Supply Chain Compromise\",\n",
        "        \"Theft of authentication information\",\n",
        "        \"Unauthorized modification: Parameters\",\n",
        "        \"Unauthorized use of equipment\",\n",
        "        \"Hijacking\",\n",
        "        \"Interception of communication\",\n",
        "        \"Man-in-the-Middle (MITM)\",\n",
        "        \"Network manipulation (Bus-Payload Link)\",\n",
        "        \"Network traffic manipulation (TC)\",\n",
        "        \"Position detection (telemetry)\",\n",
        "        \"Replay of recorded authentic communication traffic\",\n",
        "        \"Unauthorized access\",\n",
        "        \"Coercion, extortion or corruption\",\n",
        "        \"Damage/ Destruction of segment assets\",\n",
        "        \"Damage/ Destruction of the satellite via the use of ASAT / Proximity operations\",\n",
        "        \"Loss during shipping\",\n",
        "        \"Sabotage through hardware/software\",\n",
        "        \"Unauthorized physical access\",\n",
        "        \"Lack of Segregation\",\n",
        "        \"Operating errors\",\n",
        "        \"Software misconfiguration\",\n",
        "        \"Inadequate security planning / management\",\n",
        "        \"Failure of air conditioning or water supply\",\n",
        "        \"Failure of Cloud infrastructure\",\n",
        "        \"Failure of communication networks\",\n",
        "        \"Failure of power supply\",\n",
        "        \"Rogue hardware\",\n",
        "        \"Personnel Absence\",\n",
        "        \"Security services failure\",\n",
        "        \"Atmospheric hazards\",\n",
        "        \"Environmental hazards\",\n",
        "        \"Data leaks\",\n",
        "        \"Misuse of equipment\",\n",
        "        \"Negligence of asset handling security requirements\",\n",
        "        \"Refusal of actions\",\n",
        "        \"Third Party non compliance (supply chain)\",\n",
        "        \"Unauthorized access to recycled or disposed media\",\n",
        "        \"Failure to maintain information systems\",\n",
        "        \"Legacy Software\"\n",
        "    ]\n",
        "\n",
        "def get_asset_categories():\n",
        "    \"\"\"\n",
        "    Returns the asset categories for space mission components.\n",
        "    \n",
        "    Returns:\n",
        "        list: List of asset categories covering all space mission components\n",
        "    \"\"\"\n",
        "    return [\n",
        "        \"Ground_Station_Tracking\", \"Ground_Station_Ranging\", \"Ground_Station_Transmission\", \"Ground_Station_Reception\",\n",
        "        \"Mission_Control_Telemetry_Processing\", \"Mission_Control_Commanding\", \"Mission_Control_Analysis_Support\",\n",
        "        \"Data_Processing_Mission_Analysis\", \"Data_Processing_Payload_Processing\",\n",
        "        \"Remote_Terminals_Network_Access\", \"Remote_Terminals_Software_Access\",\n",
        "        \"User_Ground_Segment_Development\", \"User_Ground_Segment_Supportive\", \"User_Ground_Segment_Operations\",\n",
        "        \"Space_Platform_Electrical_Power\", \"Space_Platform_Attitude_Control\", \"Space_Platform_Communication\",\n",
        "        \"Space_Platform_Command_Data_Handling\", \"Space_Platform_Telemetry\", \"Space_Platform_Tracking\",\n",
        "        \"Space_Payload_Data_Handling_Systems\", \"Space_Payload_Communication_Module\", \"Space_Payload_Untrusted_Data_Handling\",\n",
        "        \"Link_Platform_Payload\", \"Link_Ground_Segment_Components\", \"Link_Two_Space_Systems\", \"Link_Two_Ground_WANs\",\n",
        "        \"Link_Space_Ground_Segment\", \"Link_Space_User_Segment\", \"Link_Ground_User_Segment\", \"Link_Two_Users\",\n",
        "        \"User_Transmission\", \"User_Reception\", \"User_Processing\"\n",
        "    ]\n",
        "\n",
        "# Initialize constants\n",
        "THREAT_CRITERIA = get_threat_criteria()\n",
        "ASSET_CRITERIA = get_asset_criteria()\n",
        "THREATS = get_threat_catalog()\n",
        "ASSET_CATEGORIES = get_asset_categories()\n",
        "\n",
        "print(f\"✅ Risk criteria defined\")\n",
        "print(f\"📊 Threat criteria: {len(THREAT_CRITERIA)}\")\n",
        "print(f\"📊 Asset criteria: {len(ASSET_CRITERIA)}\")\n",
        "print(f\"📊 Threats catalog: {len(THREATS)}\")\n",
        "print(f\"📊 Asset categories: {len(ASSET_CATEGORIES)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset_generation"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# SYNTHETIC DATASET GENERATION\n",
        "# ====================================================================\n",
        "\n",
        "def calculate_threat_score(threat, criterion):\n",
        "    \"\"\"\n",
        "    Calculate realistic threat scores based on threat type and criterion.\n",
        "    \n",
        "    Args:\n",
        "        threat (str): The threat name\n",
        "        criterion (str): The criterion being evaluated\n",
        "        \n",
        "    Returns:\n",
        "        int: Score between 1 and 5\n",
        "    \"\"\"\n",
        "    # Add realistic correlations based on threat types\n",
        "    if any(keyword in threat.lower() for keyword in ['destruction', 'damage', 'asat', 'sabotage', 'hardware']):\n",
        "        # Destructive/physical threats tend to have very high impact\n",
        "        base_score = np.random.normal(4.2, 0.8)\n",
        "    elif any(keyword in threat.lower() for keyword in ['supply chain', 'corruption', 'firmware', 'zero day']):\n",
        "        # Supply chain and advanced exploits have high criticality\n",
        "        base_score = np.random.normal(4.0, 0.9)\n",
        "    elif any(keyword in threat.lower() for keyword in ['dos', 'denial', 'jamming', 'interference']):\n",
        "        # Availability threats have high likelihood\n",
        "        base_score = np.random.normal(3.8, 1.0)\n",
        "    elif any(keyword in threat.lower() for keyword in ['social engineering', 'coercion', 'identity theft']):\n",
        "        # Human-based threats have specific patterns\n",
        "        base_score = np.random.normal(3.4, 1.1)\n",
        "    elif any(keyword in threat.lower() for keyword in ['malicious code', 'exploit', 'injection', 'mitm']):\n",
        "        # Software/network threats have high likelihood\n",
        "        base_score = np.random.normal(3.6, 1.0)\n",
        "    elif any(keyword in threat.lower() for keyword in ['failure', 'atmospheric', 'environmental', 'personnel absence']):\n",
        "        # Accidental/environmental threats have variable impact\n",
        "        base_score = np.random.normal(2.8, 1.2)\n",
        "    elif any(keyword in threat.lower() for keyword in ['data leak', 'breach', 'exfiltration', 'unauthorized access']):\n",
        "        # Data threats have high criticality for confidentiality\n",
        "        base_score = np.random.normal(3.7, 0.9)\n",
        "    else:\n",
        "        base_score = np.random.normal(3.0, 1.0)\n",
        "    \n",
        "    return max(1, min(5, int(round(base_score))))\n",
        "\n",
        "def calculate_asset_score(asset, criterion):\n",
        "    \"\"\"\n",
        "    Calculate realistic asset scores based on asset type and criterion.\n",
        "    \n",
        "    Args:\n",
        "        asset (str): The asset category name\n",
        "        criterion (str): The criterion being evaluated\n",
        "        \n",
        "    Returns:\n",
        "        int: Score between 1 and 5\n",
        "    \"\"\"\n",
        "    # Add realistic correlations based on asset types\n",
        "    if any(keyword in asset.lower() for keyword in ['space_platform', 'space_payload']):\n",
        "        # Space assets have maximum impact (difficult to repair/replace)\n",
        "        base_score = np.random.normal(4.5, 0.6)\n",
        "    elif any(keyword in asset.lower() for keyword in ['mission_control_commanding', 'mission_control_telemetry']):\n",
        "        # Mission control has very high criticality\n",
        "        base_score = np.random.normal(4.3, 0.7)\n",
        "    elif any(keyword in asset.lower() for keyword in ['link_platform_payload', 'link_space_ground']):\n",
        "        # Critical links have high importance\n",
        "        base_score = np.random.normal(4.0, 0.8)\n",
        "    elif any(keyword in asset.lower() for keyword in ['ground_station', 'data_processing']):\n",
        "        # Ground stations and processing have high criticality\n",
        "        base_score = np.random.normal(3.8, 0.9)\n",
        "    elif any(keyword in asset.lower() for keyword in ['remote_terminals', 'user_ground_segment']):\n",
        "        # Remote terminals and user segment have medium-high criticality\n",
        "        base_score = np.random.normal(3.4, 1.0)\n",
        "    elif any(keyword in asset.lower() for keyword in ['user_transmission', 'user_reception', 'user_processing']):\n",
        "        # End user assets have variable criticality\n",
        "        base_score = np.random.normal(3.0, 1.1)\n",
        "    else:\n",
        "        base_score = np.random.normal(3.2, 1.0)\n",
        "    \n",
        "    return max(1, min(5, int(round(base_score))))\n",
        "\n",
        "def score_to_category(score):\n",
        "    \"\"\"\n",
        "    Convert numerical score to categorical risk level.\n",
        "    \n",
        "    Args:\n",
        "        score (float): Numerical score\n",
        "        \n",
        "    Returns:\n",
        "        str: Risk category\n",
        "    \"\"\"\n",
        "    if score <= 2:\n",
        "        return \"Low\"\n",
        "    elif score <= 3:\n",
        "        return \"Medium\"\n",
        "    elif score <= 4:\n",
        "        return \"High\"\n",
        "    else:\n",
        "        return \"Very High\"\n",
        "\n",
        "def generate_risk_dataset(n_samples=10000):\n",
        "    \"\"\"\n",
        "    Generate synthetic dataset for AI model training.\n",
        "    \n",
        "    Args:\n",
        "        n_samples (int): Number of samples to generate\n",
        "        \n",
        "    Returns:\n",
        "        pd.DataFrame: Generated dataset with risk assessments\n",
        "    \"\"\"\n",
        "    print(f\"🏗️ Generating dataset with {n_samples} samples...\")\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    data = []\n",
        "    \n",
        "    for i in range(n_samples):\n",
        "        if i % (n_samples // 10) == 0:\n",
        "            print(f\"   Progress: {i/n_samples*100:.0f}%\")\n",
        "        \n",
        "        # Random selection of threat and asset\n",
        "        threat = np.random.choice(THREATS)\n",
        "        asset = np.random.choice(ASSET_CATEGORIES)\n",
        "        \n",
        "        # Generate scores for threat criteria\n",
        "        threat_scores = {}\n",
        "        for criterion in THREAT_CRITERIA.keys():\n",
        "            threat_scores[f\"threat_{criterion}\"] = calculate_threat_score(threat, criterion)\n",
        "        \n",
        "        # Generate scores for asset criteria\n",
        "        asset_scores = {}\n",
        "        for criterion in ASSET_CRITERIA.keys():\n",
        "            asset_scores[f\"asset_{criterion}\"] = calculate_asset_score(asset, criterion)\n",
        "        \n",
        "        # Calculate combined likelihood and impact\n",
        "        threat_likelihood_values = [threat_scores[f\"threat_{k}\"] for k in list(THREAT_CRITERIA.keys())[:5]]\n",
        "        threat_impact_values = [threat_scores[f\"threat_{k}\"] for k in list(THREAT_CRITERIA.keys())[5:]]\n",
        "        \n",
        "        asset_likelihood_values = [asset_scores[f\"asset_{k}\"] for k in list(ASSET_CRITERIA.keys())[:4]]\n",
        "        asset_impact_values = [asset_scores[f\"asset_{k}\"] for k in list(ASSET_CRITERIA.keys())[4:]]\n",
        "        \n",
        "        # Quadratic mean for likelihood and impact\n",
        "        combined_likelihood = np.sqrt(np.mean([np.mean(threat_likelihood_values)**2,\n",
        "                                             np.mean(asset_likelihood_values)**2]))\n",
        "        combined_impact = np.sqrt(np.mean([np.mean(threat_impact_values)**2,\n",
        "                                         np.mean(asset_impact_values)**2]))\n",
        "        \n",
        "        # Convert to categories\n",
        "        likelihood_cat = score_to_category(combined_likelihood)\n",
        "        impact_cat = score_to_category(combined_impact)\n",
        "        \n",
        "        # Calculate final risk using simplified matrix\n",
        "        risk_score = (combined_likelihood + combined_impact) / 2\n",
        "        risk_cat = score_to_category(risk_score)\n",
        "        \n",
        "        # Create record\n",
        "        record = {\n",
        "            'threat': threat,\n",
        "            'asset_category': asset,\n",
        "            'combined_likelihood': combined_likelihood,\n",
        "            'combined_impact': combined_impact,\n",
        "            'likelihood_category': likelihood_cat,\n",
        "            'impact_category': impact_cat,\n",
        "            'risk_category': risk_cat,\n",
        "            **threat_scores,\n",
        "            **asset_scores\n",
        "        }\n",
        "        \n",
        "        data.append(record)\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    print(f\"✅ Dataset generated: {len(df)} samples\")\n",
        "    \n",
        "    # Distribution analysis\n",
        "    print(f\"\\n📈 Risk category distribution:\")\n",
        "    risk_dist = df['risk_category'].value_counts()\n",
        "    for cat, count in risk_dist.items():\n",
        "        print(f\"  {cat}: {count} ({count/len(df)*100:.1f}%)\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Generate the dataset\n",
        "print(\"Starting dataset generation...\")\n",
        "dataset = generate_risk_dataset(50000)  # Reduced size for faster execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocessing"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# DATA PREPROCESSING\n",
        "# ====================================================================\n",
        "\n",
        "class RiskDataPreprocessor:\n",
        "    \"\"\"\n",
        "    Preprocessor for risk assessment data.\n",
        "    Handles encoding of categorical variables and feature preparation.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the preprocessor with empty encoders and scaler.\n",
        "        \"\"\"\n",
        "        self.label_encoders = {}\n",
        "        self.scaler = StandardScaler()\n",
        "    \n",
        "    def prepare_features_and_targets(self, df):\n",
        "        \"\"\"\n",
        "        Prepare features and targets for model training.\n",
        "        \n",
        "        Args:\n",
        "            df (pd.DataFrame): Input dataset\n",
        "            \n",
        "        Returns:\n",
        "            tuple: (features, threat_targets, asset_targets, likelihood_targets, impact_targets)\n",
        "        \"\"\"\n",
        "        print(\"🔧 Preprocessing data...\")\n",
        "        \n",
        "        # Categorical features\n",
        "        categorical_features = []\n",
        "        \n",
        "        # Encode threat\n",
        "        if 'threat_encoder' not in self.label_encoders:\n",
        "            self.label_encoders['threat_encoder'] = LabelEncoder()\n",
        "        threat_encoded = self.label_encoders['threat_encoder'].fit_transform(df['threat'])\n",
        "        categorical_features.append(threat_encoded)\n",
        "        \n",
        "        # Encode asset category\n",
        "        if 'asset_encoder' not in self.label_encoders:\n",
        "            self.label_encoders['asset_encoder'] = LabelEncoder()\n",
        "        asset_encoded = self.label_encoders['asset_encoder'].fit_transform(df['asset_category'])\n",
        "        categorical_features.append(asset_encoded)\n",
        "        \n",
        "        # Combine categorical features\n",
        "        X_categorical = np.column_stack(categorical_features)\n",
        "        \n",
        "        # Target: all risk criteria\n",
        "        threat_criteria_cols = [f\"threat_{k}\" for k in THREAT_CRITERIA.keys()]\n",
        "        asset_criteria_cols = [f\"asset_{k}\" for k in ASSET_CRITERIA.keys()]\n",
        "        \n",
        "        y_threat = df[threat_criteria_cols].values\n",
        "        y_asset = df[asset_criteria_cols].values\n",
        "        \n",
        "        # Target for likelihood/impact\n",
        "        y_likelihood = df['combined_likelihood'].values\n",
        "        y_impact = df['combined_impact'].values\n",
        "        \n",
        "        print(f\"✅ Features prepared: {X_categorical.shape}\")\n",
        "        print(f\"✅ Targets prepared: threat{y_threat.shape}, asset{y_asset.shape}\")\n",
        "        \n",
        "        return X_categorical, y_threat, y_asset, y_likelihood, y_impact\n",
        "    \n",
        "    def encode_single_input(self, threat_name, asset_name):\n",
        "        \"\"\"\n",
        "        Encode a single threat-asset pair for prediction.\n",
        "        \n",
        "        Args:\n",
        "            threat_name (str): Name of the threat\n",
        "            asset_name (str): Name of the asset\n",
        "            \n",
        "        Returns:\n",
        "            np.array: Encoded features\n",
        "        \"\"\"\n",
        "        threat_encoded = self.label_encoders['threat_encoder'].transform([threat_name])[0]\n",
        "        asset_encoded = self.label_encoders['asset_encoder'].transform([asset_name])[0]\n",
        "        return np.array([[threat_encoded, asset_encoded]])\n",
        "\n",
        "# Initialize preprocessor and prepare data\n",
        "print(\"\\n🔧 DATA PREPROCESSING\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "preprocessor = RiskDataPreprocessor()\n",
        "X, y_threat, y_asset, y_likelihood, y_impact = preprocessor.prepare_features_and_targets(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai_model"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# AI RISK ASSESSMENT SYSTEM\n",
        "# ====================================================================\n",
        "\n",
        "class AIRiskAssessmentSystem:\n",
        "    \"\"\"\n",
        "    AI-powered risk assessment system using ensemble of Random Forest models.\n",
        "    Predicts threat criteria, asset criteria, likelihood, and impact scores.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the AI system with Random Forest models.\n",
        "        \"\"\"\n",
        "        # Multi-output model for threat criteria\n",
        "        self.threat_model = MultiOutputRegressor(RandomForestRegressor(\n",
        "            n_estimators=100,\n",
        "            max_depth=15,\n",
        "            min_samples_split=5,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        ))\n",
        "        \n",
        "        # Multi-output model for asset criteria\n",
        "        self.asset_model = MultiOutputRegressor(RandomForestRegressor(\n",
        "            n_estimators=100,\n",
        "            max_depth=15,\n",
        "            min_samples_split=5,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        ))\n",
        "        \n",
        "        # Single output models for likelihood and impact\n",
        "        self.likelihood_model = RandomForestRegressor(\n",
        "            n_estimators=50,\n",
        "            max_depth=10,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        \n",
        "        self.impact_model = RandomForestRegressor(\n",
        "            n_estimators=50,\n",
        "            max_depth=10,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        \n",
        "        self.scaler = StandardScaler()\n",
        "        self.is_trained = False\n",
        "    \n",
        "    def train(self, X, y_threat, y_asset, y_likelihood, y_impact):\n",
        "        \"\"\"\n",
        "        Train all models in the system.\n",
        "        \n",
        "        Args:\n",
        "            X (np.array): Input features\n",
        "            y_threat (np.array): Threat criteria targets\n",
        "            y_asset (np.array): Asset criteria targets\n",
        "            y_likelihood (np.array): Likelihood targets\n",
        "            y_impact (np.array): Impact targets\n",
        "        \"\"\"\n",
        "        print(\"🏋️ Training AI models...\")\n",
        "        \n",
        "        # Normalize features\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "        \n",
        "        # Train models\n",
        "        print(\"  📊 Training threat criteria model...\")\n",
        "        self.threat_model.fit(X_scaled, y_threat)\n",
        "        \n",
        "        print(\"  📊 Training asset criteria model...\")\n",
        "        self.asset_model.fit(X_scaled, y_asset)\n",
        "        \n",
        "        print(\"  📊 Training likelihood model...\")\n",
        "        self.likelihood_model.fit(X_scaled, y_likelihood)\n",
        "        \n",
        "        print(\"  📊 Training impact model...\")\n",
        "        self.impact_model.fit(X_scaled, y_impact)\n",
        "        \n",
        "        self.is_trained = True\n",
        "        print(\"✅ Training completed!\")\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict all risk criteria.\n",
        "        \n",
        "        Args:\n",
        "            X (np.array): Input features\n",
        "            \n",
        "        Returns:\n",
        "            tuple: (threat_predictions, asset_predictions, likelihood_predictions, impact_predictions)\n",
        "        \"\"\"\n",
        "        if not self.is_trained:\n",
        "            raise ValueError(\"Model not trained yet!\")\n",
        "        \n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        \n",
        "        # Predictions\n",
        "        threat_pred = self.threat_model.predict(X_scaled)\n",
        "        asset_pred = self.asset_model.predict(X_scaled)\n",
        "        likelihood_pred = self.likelihood_model.predict(X_scaled)\n",
        "        impact_pred = self.impact_model.predict(X_scaled)\n",
        "        \n",
        "        # Clip values to valid range [1, 5]\n",
        "        threat_pred = np.clip(threat_pred, 1, 5)\n",
        "        asset_pred = np.clip(asset_pred, 1, 5)\n",
        "        likelihood_pred = np.clip(likelihood_pred, 1, 5)\n",
        "        impact_pred = np.clip(impact_pred, 1, 5)\n",
        "        \n",
        "        return threat_pred, asset_pred, likelihood_pred, impact_pred\n",
        "    \n",
        "    def evaluate(self, X_test, y_threat_test, y_asset_test, y_likelihood_test, y_impact_test):\n",
        "        \"\"\"\n",
        "        Evaluate model performance on test data.\n",
        "        \n",
        "        Args:\n",
        "            X_test (np.array): Test features\n",
        "            y_threat_test (np.array): Test threat targets\n",
        "            y_asset_test (np.array): Test asset targets\n",
        "            y_likelihood_test (np.array): Test likelihood targets\n",
        "            y_impact_test (np.array): Test impact targets\n",
        "            \n",
        "        Returns:\n",
        "            dict: Performance metrics for all models\n",
        "        \"\"\"\n",
        "        threat_pred, asset_pred, likelihood_pred, impact_pred = self.predict(X_test)\n",
        "        \n",
        "        metrics = {}\n",
        "        \n",
        "        # Threat model metrics\n",
        "        metrics['threat_mae'] = mean_absolute_error(y_threat_test, threat_pred)\n",
        "        metrics['threat_r2'] = r2_score(y_threat_test, threat_pred)\n",
        "        \n",
        "        # Asset model metrics\n",
        "        metrics['asset_mae'] = mean_absolute_error(y_asset_test, asset_pred)\n",
        "        metrics['asset_r2'] = r2_score(y_asset_test, asset_pred)\n",
        "        \n",
        "        # Likelihood model metrics\n",
        "        metrics['likelihood_mae'] = mean_absolute_error(y_likelihood_test, likelihood_pred)\n",
        "        metrics['likelihood_r2'] = r2_score(y_likelihood_test, likelihood_pred)\n",
        "        \n",
        "        # Impact model metrics\n",
        "        metrics['impact_mae'] = mean_absolute_error(y_impact_test, impact_pred)\n",
        "        metrics['impact_r2'] = r2_score(y_impact_test, impact_pred)\n",
        "        \n",
        "        return metrics\n",
        "    \n",
        "    def get_feature_importance(self):\n",
        "        \"\"\"\n",
        "        Get feature importance scores from the trained models.\n",
        "        \n",
        "        Returns:\n",
        "            dict: Feature importance for each model\n",
        "        \"\"\"\n",
        "        if not self.is_trained:\n",
        "            raise ValueError(\"Model not trained yet!\")\n",
        "        \n",
        "        return {\n",
        "            'likelihood': self.likelihood_model.feature_importances_,\n",
        "            'impact': self.impact_model.feature_importances_\n",
        "        }\n",
        "\n",
        "print(\"🤖 AI Risk Assessment System initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# MODEL TRAINING AND EVALUATION\n",
        "# ====================================================================\n",
        "\n",
        "def split_data(X, y_threat, y_asset, y_likelihood, y_impact, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Split data into training and testing sets.\n",
        "    \n",
        "    Args:\n",
        "        X, y_threat, y_asset, y_likelihood, y_impact: Data arrays\n",
        "        test_size (float): Proportion of data for testing\n",
        "        random_state (int): Random seed for reproducibility\n",
        "        \n",
        "    Returns:\n",
        "        tuple: Training and testing sets\n",
        "    \"\"\"\n",
        "    # Split data\n",
        "    X_train, X_test, y_threat_train, y_threat_test = train_test_split(\n",
        "        X, y_threat, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "    \n",
        "    _, _, y_asset_train, y_asset_test = train_test_split(\n",
        "        X, y_asset, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "    \n",
        "    _, _, y_likelihood_train, y_likelihood_test = train_test_split(\n",
        "        X, y_likelihood, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "    \n",
        "    _, _, y_impact_train, y_impact_test = train_test_split(\n",
        "        X, y_impact, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "    \n",
        "    return (X_train, X_test, y_threat_train, y_threat_test, \n",
        "            y_asset_train, y_asset_test, y_likelihood_train, y_likelihood_test, \n",
        "            y_impact_train, y_impact_test)\n",
        "\n",
        "def print_evaluation_results(metrics):\n",
        "    \"\"\"\n",
        "    Print model evaluation results in a formatted way.\n",
        "    \n",
        "    Args:\n",
        "        metrics (dict): Dictionary containing performance metrics\n",
        "    \"\"\"\n",
        "    print(\"🎯 EVALUATION RESULTS:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"  Threat Model - MAE: {metrics['threat_mae']:.3f}, R²: {metrics['threat_r2']:.3f}\")\n",
        "    print(f\"  Asset Model - MAE: {metrics['asset_mae']:.3f}, R²: {metrics['asset_r2']:.3f}\")\n",
        "    print(f\"  Likelihood Model - MAE: {metrics['likelihood_mae']:.3f}, R²: {metrics['likelihood_r2']:.3f}\")\n",
        "    print(f\"  Impact Model - MAE: {metrics['impact_mae']:.3f}, R²: {metrics['impact_r2']:.3f}\")\n",
        "    \n",
        "    # Calculate overall performance\n",
        "    avg_mae = np.mean([metrics['threat_mae'], metrics['asset_mae'], \n",
        "                       metrics['likelihood_mae'], metrics['impact_mae']])\n",
        "    avg_r2 = np.mean([metrics['threat_r2'], metrics['asset_r2'], \n",
        "                      metrics['likelihood_r2'], metrics['impact_r2']])\n",
        "    \n",
        "    print(f\"\\n📊 Overall Performance:\")\n",
        "    print(f\"  Average MAE: {avg_mae:.3f}\")\n",
        "    print(f\"  Average R²: {avg_r2:.3f}\")\n",
        "\n",
        "# Split data into training and testing sets\n",
        "print(\"\\n🏋️ MODEL TRAINING\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "train_test_data = split_data(X, y_threat, y_asset, y_likelihood, y_impact)\n",
        "(X_train, X_test, y_threat_train, y_threat_test, \n",
        " y_asset_train, y_asset_test, y_likelihood_train, y_likelihood_test, \n",
        " y_impact_train, y_impact_test) = train_test_data\n",
        "\n",
        "print(f\"📊 Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"📊 Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Initialize and train the AI system\n",
        "ai_system = AIRiskAssessmentSystem()\n",
        "ai_system.train(X_train, y_threat_train, y_asset_train, y_likelihood_train, y_impact_train)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\n📊 MODEL EVALUATION\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "metrics = ai_system.evaluate(X_test, y_threat_test, y_asset_test, y_likelihood_test, y_impact_test)\n",
        "print_evaluation_results(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "automated_assessment"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# AUTOMATED RISK ASSESSMENT SYSTEM\n",
        "# ====================================================================\n",
        "\n",
        "def automated_risk_assessment(threat_name, asset_name, ai_system, preprocessor):\n",
        "    \"\"\"\n",
        "    Perform automated risk assessment using AI system.\n",
        "    \n",
        "    Args:\n",
        "        threat_name (str): Name of the threat\n",
        "        asset_name (str): Name of the asset\n",
        "        ai_system (AIRiskAssessmentSystem): Trained AI system\n",
        "        preprocessor (RiskDataPreprocessor): Data preprocessor\n",
        "        \n",
        "    Returns:\n",
        "        dict: Complete risk assessment results\n",
        "    \"\"\"\n",
        "    print(f\"\\n🔍 AUTOMATED RISK ASSESSMENT\")\n",
        "    print(f\"🎯 Threat: {threat_name}\")\n",
        "    print(f\"🏗️ Asset: {asset_name}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Prepare input\n",
        "    try:\n",
        "        X_input = preprocessor.encode_single_input(threat_name, asset_name)\n",
        "    except ValueError as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        return None\n",
        "    \n",
        "    # Make predictions\n",
        "    threat_pred, asset_pred, likelihood_pred, impact_pred = ai_system.predict(X_input)\n",
        "    \n",
        "    # Convert to categories\n",
        "    likelihood_cat = score_to_category(likelihood_pred[0])\n",
        "    impact_cat = score_to_category(impact_pred[0])\n",
        "    \n",
        "    # Calculate final risk\n",
        "    risk_score = (likelihood_pred[0] + impact_pred[0]) / 2\n",
        "    risk_cat = score_to_category(risk_score)\n",
        "    \n",
        "    # Display results\n",
        "    print(f\"📈 Likelihood: {likelihood_pred[0]:.2f} ({likelihood_cat})\")\n",
        "    print(f\"📈 Impact: {impact_pred[0]:.2f} ({impact_cat})\")\n",
        "    print(f\"⚠️ Risk Level: {risk_score:.2f} ({risk_cat})\")\n",
        "    \n",
        "    print(f\"\\n📊 Threat Criteria Details:\")\n",
        "    for i, criterion in enumerate(THREAT_CRITERIA.keys()):\n",
        "        print(f\"  {criterion}: {threat_pred[0][i]:.2f}\")\n",
        "    \n",
        "    print(f\"\\n📊 Asset Criteria Details:\")\n",
        "    for i, criterion in enumerate(ASSET_CRITERIA.keys()):\n",
        "        print(f\"  {criterion}: {asset_pred[0][i]:.2f}\")\n",
        "    \n",
        "    return {\n",
        "        'threat': threat_name,\n",
        "        'asset': asset_name,\n",
        "        'likelihood': likelihood_pred[0],\n",
        "        'impact': impact_pred[0],\n",
        "        'risk_score': risk_score,\n",
        "        'risk_category': risk_cat,\n",
        "        'threat_criteria': dict(zip(THREAT_CRITERIA.keys(), threat_pred[0])),\n",
        "        'asset_criteria': dict(zip(ASSET_CRITERIA.keys(), asset_pred[0]))\n",
        "    }\n",
        "\n",
        "def run_test_scenarios(ai_system, preprocessor):\n",
        "    \"\"\"\n",
        "    Run predefined test scenarios to demonstrate the system.\n",
        "    \n",
        "    Args:\n",
        "        ai_system (AIRiskAssessmentSystem): Trained AI system\n",
        "        preprocessor (RiskDataPreprocessor): Data preprocessor\n",
        "        \n",
        "    Returns:\n",
        "        list: Results from all test scenarios\n",
        "    \"\"\"\n",
        "    # Define test scenarios\n",
        "    test_scenarios = [\n",
        "        (\"Data modification\", \"Space_Platform_Communication\"),\n",
        "        (\"Jamming\", \"Ground_Station_Tracking\"),\n",
        "        (\"Malicious code/ software/activity: Network exploit\", \"Mission_Control_Commanding\"),\n",
        "        (\"Supply Chain Compromise\", \"Space_Payload_Data_Handling_Systems\"),\n",
        "        (\"Damage/ Destruction of the satellite via the use of ASAT / Proximity operations\", \"Space_Platform_Electrical_Power\")\n",
        "    ]\n",
        "    \n",
        "    results = []\n",
        "    for threat, asset in test_scenarios:\n",
        "        result = automated_risk_assessment(threat, asset, ai_system, preprocessor)\n",
        "        if result:\n",
        "            results.append(result)\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Run test scenarios\n",
        "print(\"\\n🧪 SYSTEM TESTING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "test_results = run_test_scenarios(ai_system, preprocessor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visualization"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# RESULTS VISUALIZATION\n",
        "# ====================================================================\n",
        "\n",
        "def create_performance_visualizations(metrics, test_results, ai_system):\n",
        "    \"\"\"\n",
        "    Create comprehensive visualizations of system performance and results.\n",
        "    \n",
        "    Args:\n",
        "        metrics (dict): Model performance metrics\n",
        "        test_results (list): Results from test scenarios\n",
        "        ai_system (AIRiskAssessmentSystem): Trained AI system\n",
        "    \"\"\"\n",
        "    print(\"\\n📈 CREATING VISUALIZATIONS\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Create figure with subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('AI Risk Assessment System - Performance Dashboard', fontsize=16)\n",
        "    \n",
        "    # 1. Model Performance - MAE\n",
        "    model_names = ['Threat', 'Asset', 'Likelihood', 'Impact']\n",
        "    mae_scores = [metrics['threat_mae'], metrics['asset_mae'],\n",
        "                  metrics['likelihood_mae'], metrics['impact_mae']]\n",
        "    \n",
        "    axes[0,0].bar(model_names, mae_scores, color='lightcoral', alpha=0.7)\n",
        "    axes[0,0].set_title('Mean Absolute Error (Lower is Better)')\n",
        "    axes[0,0].set_ylabel('MAE')\n",
        "    axes[0,0].tick_params(axis='x', rotation=45)\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Model Performance - R²\n",
        "    r2_scores = [metrics['threat_r2'], metrics['asset_r2'],\n",
        "                 metrics['likelihood_r2'], metrics['impact_r2']]\n",
        "    \n",
        "    axes[0,1].bar(model_names, r2_scores, color='lightblue', alpha=0.7)\n",
        "    axes[0,1].set_title('R² Score (Higher is Better)')\n",
        "    axes[0,1].set_ylabel('R²')\n",
        "    axes[0,1].tick_params(axis='x', rotation=45)\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Test Scenario Results\n",
        "    if test_results:\n",
        "        test_names = [f\"{r['threat'][:15]}...\\n{r['asset'][:15]}...\" for r in test_results]\n",
        "        risk_scores = [r['risk_score'] for r in test_results]\n",
        "        likelihood_scores = [r['likelihood'] for r in test_results]\n",
        "        impact_scores = [r['impact'] for r in test_results]\n",
        "        \n",
        "        x = np.arange(len(test_names))\n",
        "        width = 0.25\n",
        "        \n",
        "        axes[1,0].bar(x - width, risk_scores, width, label='Risk Score', color='red', alpha=0.7)\n",
        "        axes[1,0].bar(x, likelihood_scores, width, label='Likelihood', color='orange', alpha=0.7)\n",
        "        axes[1,0].bar(x + width, impact_scores, width, label='Impact', color='yellow', alpha=0.7)\n",
        "        axes[1,0].set_title('Test Scenario Results')\n",
        "        axes[1,0].set_ylabel('Score')\n",
        "        axes[1,0].set_xticks(x)\n",
        "        axes[1,0].set_xticklabels(test_names, rotation=45, ha='right', fontsize=8)\n",
        "        axes[1,0].legend()\n",
        "        axes[1,0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Feature Importance\n",
        "    try:\n",
        "        feature_importance = ai_system.get_feature_importance()\n",
        "        feature_names = ['Threat Type', 'Asset Category']\n",
        "        \n",
        "        axes[1,1].bar(feature_names, feature_importance['likelihood'], \n",
        "                     color='lightgreen', alpha=0.7, label='Likelihood Model')\n",
        "        axes[1,1].set_title('Feature Importance')\n",
        "        axes[1,1].set_ylabel('Importance')\n",
        "        axes[1,1].grid(True, alpha=0.3)\n",
        "        axes[1,1].legend()\n",
        "    except Exception as e:\n",
        "        axes[1,1].text(0.5, 0.5, f'Feature importance\\nnot available\\n{str(e)}', \n",
        "                      ha='center', va='center', transform=axes[1,1].transAxes)\n",
        "        axes[1,1].set_title('Feature Importance')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def create_risk_distribution_plot(dataset):\n",
        "    \"\"\"\n",
        "    Create a visualization of risk distribution in the dataset.\n",
        "    \n",
        "    Args:\n",
        "        dataset (pd.DataFrame): The dataset to analyze\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    fig.suptitle('Risk Distribution Analysis', fontsize=16)\n",
        "    \n",
        "    # Risk category distribution\n",
        "    risk_counts = dataset['risk_category'].value_counts()\n",
        "    axes[0].pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%')\n",
        "    axes[0].set_title('Risk Category Distribution')\n",
        "    \n",
        "    # Likelihood vs Impact scatter\n",
        "    scatter = axes[1].scatter(dataset['combined_likelihood'], dataset['combined_impact'], \n",
        "                             alpha=0.6, c=dataset['combined_likelihood'] + dataset['combined_impact'], \n",
        "                             cmap='Reds')\n",
        "    axes[1].set_xlabel('Likelihood')\n",
        "    axes[1].set_ylabel('Impact')\n",
        "    axes[1].set_title('Likelihood vs Impact')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    plt.colorbar(scatter, ax=axes[1], label='Combined Score')\n",
        "    \n",
        "    # Risk score distribution\n",
        "    risk_scores = (dataset['combined_likelihood'] + dataset['combined_impact']) / 2\n",
        "    axes[2].hist(risk_scores, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    axes[2].set_xlabel('Risk Score')\n",
        "    axes[2].set_ylabel('Frequency')\n",
        "    axes[2].set_title('Risk Score Distribution')\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Create visualizations\n",
        "create_performance_visualizations(metrics, test_results, ai_system)\n",
        "create_risk_distribution_plot(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utility_functions"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ====================================================================\n",
        "\n",
        "def save_ai_system(ai_system, preprocessor, filename=\"risk_assessment_ai_model\"):\n",
        "    \"\"\"\n",
        "    Save the trained AI system for future use.\n",
        "    \n",
        "    Args:\n",
        "        ai_system (AIRiskAssessmentSystem): Trained AI system\n",
        "        preprocessor (RiskDataPreprocessor): Data preprocessor\n",
        "        filename (str): Base filename for saving\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import joblib\n",
        "        \n",
        "        model_data = {\n",
        "            'ai_system': ai_system,\n",
        "            'preprocessor': preprocessor,\n",
        "            'threat_criteria': THREAT_CRITERIA,\n",
        "            'asset_criteria': ASSET_CRITERIA,\n",
        "            'threats': THREATS,\n",
        "            'asset_categories': ASSET_CATEGORIES\n",
        "        }\n",
        "        \n",
        "        joblib.dump(model_data, f\"{filename}.pkl\")\n",
        "        print(f\"✅ System saved to {filename}.pkl\")\n",
        "        \n",
        "    except ImportError:\n",
        "        print(\"⚠️ joblib not available for saving. Install with: pip install joblib\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving system: {e}\")\n",
        "\n",
        "def load_ai_system(filename=\"risk_assessment_ai_model\"):\n",
        "    \"\"\"\n",
        "    Load a previously saved AI system.\n",
        "    \n",
        "    Args:\n",
        "        filename (str): Base filename for loading\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (ai_system, preprocessor, criteria)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import joblib\n",
        "        \n",
        "        model_data = joblib.load(f\"{filename}.pkl\")\n",
        "        print(f\"✅ System loaded from {filename}.pkl\")\n",
        "        \n",
        "        return (model_data['ai_system'], model_data['preprocessor'], \n",
        "                model_data['threat_criteria'], model_data['asset_criteria'])\n",
        "                \n",
        "    except ImportError:\n",
        "        print(\"⚠️ joblib not available for loading. Install with: pip install joblib