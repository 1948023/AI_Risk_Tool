{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a790acd0",
   "metadata": {},
   "source": [
    "# üöÄ Advanced AI Risk Assessment System for Space Cybersecurity\n",
    "## Automated Risk Evaluation based on CRAALSP Framework\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/1948023/CRAALSP/blob/main/AI_Risk_Assessment_Advanced.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "---\n",
    "\n",
    "### üìã **Obiettivo del Notebook**\n",
    "\n",
    "Questo notebook implementa un sistema di intelligenza artificiale avanzato per automatizzare il processo di **risk assessment** in ambito cybersecurity spaziale, basato sul framework **CRAALSP** (Cybersecurity Risk Assessment Algorithm for Launch Service Providers).\n",
    "\n",
    "### üéØ **Caratteristiche Principali**\n",
    "\n",
    "- **Analisi automatica** di 57+ minacce cybersecurity spaziali\n",
    "- **Valutazione di 33+ categorie** di asset critici\n",
    "- **Sistema di scoring** basato su 7 criteri per minacce + 9 criteri per asset\n",
    "- **Machine Learning** per predizioni accurate di rischio\n",
    "- **Compatibilit√† Google Colab** per training su cloud\n",
    "\n",
    "### üîß **Framework di Riferimento**\n",
    "\n",
    "Il modello si basa sul tool `2-Risk_Assessment.py` del progetto CRAALSP e utilizza:\n",
    "- **7 Criteri per Minacce**: Vulnerability, Mitigation, Detection, Access, Privilege, Response, Resilience\n",
    "- **9 Criteri per Asset**: Dependency, Penetration, Maturity, Trust, Performance, Schedule, Costs, Reputation, Recovery\n",
    "- **Matrice di Rischio ISO 27005** per valutazioni finali\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd15ce",
   "metadata": {},
   "source": [
    "## üì¶ 1. Installazione e Import delle Librerie\n",
    "\n",
    "Per prima cosa installiamo e importiamo tutte le librerie necessarie per il machine learning e l'elaborazione dei dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ca32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installazione delle librerie necessarie per Google Colab\n",
    "!pip install --quiet tensorflow scikit-learn pandas numpy matplotlib seaborn plotly\n",
    "!pip install --quiet transformers torch torchvision torchaudio\n",
    "!pip install --quiet xgboost lightgbm catboost\n",
    "!pip install --quiet optuna  # Per ottimizzazione iperparametri\n",
    "!pip install --quiet pickle-mixin\n",
    "\n",
    "print(\"‚úÖ Tutte le librerie sono state installate con successo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c4b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import delle librerie principali\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, classification_report, confusion_matrix\n",
    "from sklearn.multioutput import MultiOutputRegressor, MultiOutputClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, callbacks\n",
    "\n",
    "# Advanced ML\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "# Utility\n",
    "import pickle\n",
    "import json\n",
    "import warnings\n",
    "import datetime\n",
    "import io\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# NLP\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Suppression warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"üìä Tutte le librerie importate con successo!\")\n",
    "print(f\"üî• TensorFlow version: {tf.__version__}\")\n",
    "print(f\"üêç Pandas version: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efafa067",
   "metadata": {},
   "source": [
    "## üìã 2. Caricamento e Preparazione dei Dati\n",
    "\n",
    "In questa sezione carichiamo i dati dal framework CRAALSP e definiamo la struttura del dataset per l'addestramento dell'AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione completa delle minacce basata su Threat.csv del framework CRAALSP\n",
    "THREATS = [\n",
    "    \"Abuse of leaked data\", \"Abuse / Falsification of right\", \n",
    "    \"Compromising confidential information (data breaches): Exfiltration\",\n",
    "    \"Denial of Service (DoS)\", \"Data modification\", \"Electromagnetic interference\",\n",
    "    \"Firmware corruption\", \"Identity Theft\", \"Jamming\",\n",
    "    \"Malicious code / software / activity: Cryptographic exploit\",\n",
    "    \"Malicious code / software / activity: Malicious injection\",\n",
    "    \"Malicious code / software / activity: Network exploit\",\n",
    "    \"Malicious code / software / activity: Software and vulnerabilities' exploit\",\n",
    "    \"Manipulation of hardware and software: Zero Day exploit\",\n",
    "    \"Preventing services\", \"Resource exhaustion\", \"Seizure of control: Satellite bus\",\n",
    "    \"Social Engineering\", \"Spoofing\", \"Supply Chain Compromise\",\n",
    "    \"Theft of authentication information\", \"Unauthorized modification: Parameters\",\n",
    "    \"Unauthorized use of equipment\", \"Hijacking\", \"Interception of communication\",\n",
    "    \"Man-in-the-Middle (MITM)\", \"Network manipulation (Bus-Payload Link)\",\n",
    "    \"Network traffic manipulation (TC)\", \"Position detection (telemetry)\",\n",
    "    \"Replay of recorded authentic communication traffic\", \"Unauthorized access\",\n",
    "    \"Coercion, extortion or corruption\", \"Damage / Destruction of segment assets\",\n",
    "    \"Damage / Destruction of the satellite via the use of ASAT / Proximity operations\",\n",
    "    \"Loss during shipping\", \"Sabotage through hardware/software\",\n",
    "    \"Unauthorized physical access\", \"Lack of Segregation\", \"Operating errors\",\n",
    "    \"Software misconfiguration\", \"Inadequate security planning / management\",\n",
    "    \"Failure of air conditioning or water supply\", \"Failure of Cloud infrastructure\",\n",
    "    \"Failure of communication networks\", \"Failure of power supply\", \"Rogue hardware\",\n",
    "    \"Personnel Absence\", \"Security services failure\", \"Atmospheric hazards\",\n",
    "    \"Environmental hazards\", \"Data leaks\", \"Misuse of equipment\",\n",
    "    \"Negligence of asset handling security requirements\", \"Refusal of actions\",\n",
    "    \"Third Party non compliance (supply chain)\",\n",
    "    \"Unauthorized access to recycled or disposed media\",\n",
    "    \"Failure to maintain information systems\", \"Legacy Software\"\n",
    "]\n",
    "\n",
    "# Definizione completa degli asset basata su Asset.csv del framework CRAALSP\n",
    "ASSET_CATEGORIES = [\n",
    "    # Ground Segment\n",
    "    (\"Ground Segment\", \"Ground Station\", \"Ground Station Tracking\"),\n",
    "    (\"Ground Segment\", \"Ground Station\", \"Ground Station Ranging\"),\n",
    "    (\"Ground Segment\", \"Ground Station\", \"Ground Station Transmission\"),\n",
    "    (\"Ground Segment\", \"Ground Station\", \"Ground Station Reception\"),\n",
    "    \n",
    "    # Mission Control\n",
    "    (\"Ground Segment\", \"Mission Control\", \"Mission Control Telemetry Processing\"),\n",
    "    (\"Ground Segment\", \"Mission Control\", \"Mission Control Commanding\"),\n",
    "    (\"Ground Segment\", \"Mission Control\", \"Mission Control Analysis Support\"),\n",
    "    \n",
    "    # Data Processing\n",
    "    (\"Ground Segment\", \"Data Processing\", \"Data Processing Mission Analysis\"),\n",
    "    (\"Ground Segment\", \"Data Processing\", \"Data Processing Payload Processing\"),\n",
    "    \n",
    "    # Remote Terminals\n",
    "    (\"Ground Segment\", \"Remote Terminals\", \"Remote Terminals Network Access\"),\n",
    "    (\"Ground Segment\", \"Remote Terminals\", \"Remote Terminals Software Access\"),\n",
    "    \n",
    "    # User Ground Segment\n",
    "    (\"User Segment\", \"User Ground Segment\", \"User Ground Segment Development\"),\n",
    "    (\"User Segment\", \"User Ground Segment\", \"User Ground Segment Supportive\"),\n",
    "    (\"User Segment\", \"User Ground Segment\", \"User Ground Segment Operations\"),\n",
    "    \n",
    "    # Space Platform\n",
    "    (\"Space Segment\", \"Space Platform\", \"Space Platform Electrical Power\"),\n",
    "    (\"Space Segment\", \"Space Platform\", \"Space Platform Attitude Control\"),\n",
    "    (\"Space Segment\", \"Space Platform\", \"Space Platform Communication\"),\n",
    "    (\"Space Segment\", \"Space Platform\", \"Space Platform Command Data Handling\"),\n",
    "    (\"Space Segment\", \"Space Platform\", \"Space Platform Telemetry\"),\n",
    "    (\"Space Segment\", \"Space Platform\", \"Space Platform Tracking\"),\n",
    "    \n",
    "    # Space Payload\n",
    "    (\"Space Segment\", \"Space Payload\", \"Space Payload Data Handling Systems\"),\n",
    "    (\"Space Segment\", \"Space Payload\", \"Space Payload Communication Module\"),\n",
    "    (\"Space Segment\", \"Space Payload\", \"Space Payload Untrusted Data Handling\"),\n",
    "    \n",
    "    # Links\n",
    "    (\"Communication Links\", \"Inter-segment Links\", \"Link Platform Payload\"),\n",
    "    (\"Communication Links\", \"Inter-segment Links\", \"Link Ground Segment Components\"),\n",
    "    (\"Communication Links\", \"Inter-segment Links\", \"Link Two Space Systems\"),\n",
    "    (\"Communication Links\", \"Inter-segment Links\", \"Link Two Ground WANs\"),\n",
    "    (\"Communication Links\", \"Inter-segment Links\", \"Link Space Ground Segment\"),\n",
    "    (\"Communication Links\", \"Inter-segment Links\", \"Link Space User Segment\"),\n",
    "    (\"Communication Links\", \"Inter-segment Links\", \"Link Ground User Segment\"),\n",
    "    (\"Communication Links\", \"Inter-segment Links\", \"Link Two Users\"),\n",
    "    \n",
    "    # User Equipment\n",
    "    (\"User Segment\", \"User Equipment\", \"User Transmission\"),\n",
    "    (\"User Segment\", \"User Equipment\", \"User Reception\"),\n",
    "    (\"User Segment\", \"User Equipment\", \"User Processing\")\n",
    "]\n",
    "\n",
    "# Criteri per le minacce (7 criteri: 5 likelihood + 2 impact)\n",
    "THREAT_CRITERIA = [\n",
    "    \"Vulnerability Effectiveness\", \"Mitigation Presence\", \"Detection Probability\", \n",
    "    \"Access Complexity\", \"Privilege Requirement\", \"Response Delay\", \"Resilience Impact\"\n",
    "]\n",
    "\n",
    "# Criteri per gli asset (9 criteri: 4 likelihood + 5 impact)\n",
    "ASSET_CRITERIA = [\n",
    "    \"Dependency\", \"Penetration\", \"Cyber Maturity\", \"Trust\", \n",
    "    \"Performance\", \"Schedule\", \"Costs\", \"Reputation\", \"Recovery\"\n",
    "]\n",
    "\n",
    "# Matrice di rischio ISO 27005\n",
    "RISK_LEVELS = [\"Very Low\", \"Low\", \"Medium\", \"High\", \"Very High\"]\n",
    "SCORES = [1, 2, 3, 4, 5]\n",
    "\n",
    "print(f\"üìä Dataset caricato con successo!\")\n",
    "print(f\"üéØ Minacce totali: {len(THREATS)}\")\n",
    "print(f\"üè¢ Asset totali: {len(ASSET_CATEGORIES)}\")\n",
    "print(f\"üìã Criteri minacce: {len(THREAT_CRITERIA)}\")\n",
    "print(f\"üìã Criteri asset: {len(ASSET_CRITERIA)}\")\n",
    "print(f\"üé≤ Combinazioni possibili: {len(THREATS) * len(ASSET_CATEGORIES):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2facf535",
   "metadata": {},
   "source": [
    "## üîß 3. Preprocessing e Feature Engineering\n",
    "\n",
    "Creiamo le feature necessarie per l'addestramento del modello basate sulla categorizzazione semantica delle minacce e degli asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedFeatureEngineer:\n",
    "    \"\"\"Sistema avanzato di feature engineering per il risk assessment spaziale\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.setup_threat_categories()\n",
    "        self.setup_asset_categories()\n",
    "        self.setup_semantic_features()\n",
    "    \n",
    "    def setup_threat_categories(self):\n",
    "        \"\"\"Categorizzazione semantica delle minacce\"\"\"\n",
    "        self.threat_categories = {\n",
    "            'cyber_attack': [\n",
    "                'Malicious code / software / activity: Network exploit',\n",
    "                'Malicious code / software / activity: Software and vulnerabilities exploit',\n",
    "                'Malicious code / software / activity: Cryptographic exploit',\n",
    "                'Malicious code / software / activity: Malicious injection',\n",
    "                'Manipulation of hardware and software: Zero Day exploit',\n",
    "                'Man-in-the-Middle (MITM)', 'Hijacking', 'Spoofing'\n",
    "            ],\n",
    "            'data_compromise': [\n",
    "                'Compromising confidential information (data breaches): Exfiltration',\n",
    "                'Data modification', 'Data leaks', 'Abuse of leaked data',\n",
    "                'Unauthorized modification: Parameters'\n",
    "            ],\n",
    "            'access_control': [\n",
    "                'Unauthorized access', 'Theft of authentication information',\n",
    "                'Abuse / Falsification of right', 'Unauthorized use of equipment'\n",
    "            ],\n",
    "            'communication_attack': [\n",
    "                'Jamming', 'Interception of communication', 'Network manipulation (Bus-Payload Link)',\n",
    "                'Network traffic manipulation (TC)', 'Position detection (telemetry)',\n",
    "                'Replay of recorded authentic communication traffic'\n",
    "            ],\n",
    "            'service_disruption': [\n",
    "                'Denial of Service (DoS)', 'Preventing services', 'Resource exhaustion',\n",
    "                'Seizure of control: Satellite bus'\n",
    "            ],\n",
    "            'physical_attack': [\n",
    "                'Damage / Destruction of segment assets',\n",
    "                'Damage / Destruction of the satellite via the use of ASAT / Proximity operations',\n",
    "                'Sabotage through hardware/software', 'Unauthorized physical access'\n",
    "            ],\n",
    "            'supply_chain': [\n",
    "                'Supply Chain Compromise', 'Third Party non compliance (supply chain)',\n",
    "                'Rogue hardware', 'Loss during shipping'\n",
    "            ],\n",
    "            'human_factor': [\n",
    "                'Social Engineering', 'Identity Theft', 'Coercion, extortion or corruption',\n",
    "                'Operating errors', 'Misuse of equipment', 'Negligence of asset handling security requirements',\n",
    "                'Personnel Absence', 'Refusal of actions'\n",
    "            ],\n",
    "            'system_failure': [\n",
    "                'Failure of communication networks', 'Failure of power supply',\n",
    "                'Failure of air conditioning or water supply', 'Failure of Cloud infrastructure',\n",
    "                'Security services failure', 'Failure to maintain information systems'\n",
    "            ],\n",
    "            'environmental': [\n",
    "                'Electromagnetic interference', 'Atmospheric hazards', 'Environmental hazards'\n",
    "            ],\n",
    "            'configuration': [\n",
    "                'Software misconfiguration', 'Firmware corruption', 'Legacy Software',\n",
    "                'Inadequate security planning / management', 'Lack of Segregation',\n",
    "                'Unauthorized access to recycled or disposed media'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def setup_asset_categories(self):\n",
    "        \"\"\"Categorizzazione semantica degli asset\"\"\"\n",
    "        self.asset_categories = {\n",
    "            'criticality': {\n",
    "                'critical': ['Space Platform Electrical Power', 'Space Platform Command Data Handling',\n",
    "                           'Mission Control Commanding', 'Space Platform Communication'],\n",
    "                'high': ['Space Platform Attitude Control', 'Space Platform Telemetry',\n",
    "                        'Mission Control Telemetry Processing', 'Space Platform Tracking'],\n",
    "                'medium': ['Ground Station Transmission', 'Ground Station Reception',\n",
    "                          'Data Processing Mission Analysis', 'Space Payload Communication Module'],\n",
    "                'low': ['User Ground Segment Development', 'Remote Terminals Network Access',\n",
    "                       'User Ground Segment Supportive']\n",
    "            },\n",
    "            'exposure': {\n",
    "                'high': ['Ground Station Reception', 'User Reception', 'Link Space Ground Segment',\n",
    "                        'Link Space User Segment', 'User Transmission'],\n",
    "                'medium': ['Ground Station Transmission', 'Space Platform Communication',\n",
    "                          'Link Two Space Systems', 'Link Ground User Segment'],\n",
    "                'low': ['Space Platform Electrical Power', 'Mission Control Analysis Support',\n",
    "                       'Data Processing Payload Processing']\n",
    "            },\n",
    "            'segment': {\n",
    "                'space': ['Space Platform Electrical Power', 'Space Platform Attitude Control',\n",
    "                         'Space Platform Communication', 'Space Platform Command Data Handling',\n",
    "                         'Space Platform Telemetry', 'Space Platform Tracking',\n",
    "                         'Space Payload Data Handling Systems', 'Space Payload Communication Module',\n",
    "                         'Space Payload Untrusted Data Handling'],\n",
    "                'ground': ['Ground Station Tracking', 'Ground Station Ranging',\n",
    "                          'Ground Station Transmission', 'Ground Station Reception',\n",
    "                          'Mission Control Telemetry Processing', 'Mission Control Commanding',\n",
    "                          'Mission Control Analysis Support', 'Data Processing Mission Analysis',\n",
    "                          'Data Processing Payload Processing'],\n",
    "                'user': ['User Ground Segment Development', 'User Ground Segment Supportive',\n",
    "                        'User Ground Segment Operations', 'User Transmission',\n",
    "                        'User Reception', 'User Processing'],\n",
    "                'link': ['Link Platform Payload', 'Link Ground Segment Components',\n",
    "                        'Link Two Space Systems', 'Link Two Ground WANs',\n",
    "                        'Link Space Ground Segment', 'Link Space User Segment',\n",
    "                        'Link Ground User Segment', 'Link Two Users']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def setup_semantic_features(self):\n",
    "        \"\"\"Definisce feature semantiche avanzate\"\"\"\n",
    "        self.threat_keywords = {\n",
    "            'malicious': ['malicious', 'exploit', 'attack', 'injection', 'compromise'],\n",
    "            'unauthorized': ['unauthorized', 'theft', 'abuse', 'falsification'],\n",
    "            'disruption': ['denial', 'jamming', 'disruption', 'preventing', 'exhaustion'],\n",
    "            'physical': ['destruction', 'damage', 'sabotage', 'physical'],\n",
    "            'technical': ['software', 'hardware', 'network', 'cryptographic', 'firmware'],\n",
    "            'human': ['social', 'identity', 'coercion', 'negligence', 'error']\n",
    "        }\n",
    "    \n",
    "    def get_threat_category(self, threat_name):\n",
    "        \"\"\"Ottiene la categoria principale di una minaccia\"\"\"\n",
    "        for category, threats in self.threat_categories.items():\n",
    "            if threat_name in threats:\n",
    "                return category\n",
    "        return 'other'\n",
    "    \n",
    "    def get_asset_properties(self, asset_name):\n",
    "        \"\"\"Ottiene le propriet√† di un asset\"\"\"\n",
    "        properties = {}\n",
    "        \n",
    "        # Criticality\n",
    "        for level, assets in self.asset_categories['criticality'].items():\n",
    "            if asset_name in assets:\n",
    "                properties['criticality'] = level\n",
    "                break\n",
    "        else:\n",
    "            properties['criticality'] = 'medium'\n",
    "        \n",
    "        # Exposure\n",
    "        for level, assets in self.asset_categories['exposure'].items():\n",
    "            if asset_name in assets:\n",
    "                properties['exposure'] = level\n",
    "                break\n",
    "        else:\n",
    "            properties['exposure'] = 'medium'\n",
    "        \n",
    "        # Segment\n",
    "        for segment, assets in self.asset_categories['segment'].items():\n",
    "            if asset_name in assets:\n",
    "                properties['segment'] = segment\n",
    "                break\n",
    "        else:\n",
    "            properties['segment'] = 'ground'\n",
    "        \n",
    "        return properties\n",
    "    \n",
    "    def calculate_threat_asset_affinity(self, threat_name, asset_name):\n",
    "        \"\"\"Calcola l'affinit√† tra minaccia e asset\"\"\"\n",
    "        threat_category = self.get_threat_category(threat_name)\n",
    "        asset_properties = self.get_asset_properties(asset_name)\n",
    "        \n",
    "        # Matrice di affinit√† threat-asset\n",
    "        affinity_matrix = {\n",
    "            'cyber_attack': {'space': 0.9, 'ground': 0.8, 'user': 0.7, 'link': 0.85},\n",
    "            'data_compromise': {'space': 0.85, 'ground': 0.9, 'user': 0.8, 'link': 0.75},\n",
    "            'communication_attack': {'space': 0.95, 'ground': 0.7, 'user': 0.8, 'link': 0.95},\n",
    "            'service_disruption': {'space': 0.9, 'ground': 0.8, 'user': 0.6, 'link': 0.85},\n",
    "            'physical_attack': {'space': 0.95, 'ground': 0.7, 'user': 0.5, 'link': 0.3},\n",
    "            'supply_chain': {'space': 0.8, 'ground': 0.9, 'user': 0.7, 'link': 0.4},\n",
    "            'human_factor': {'space': 0.3, 'ground': 0.9, 'user': 0.8, 'link': 0.2},\n",
    "            'system_failure': {'space': 0.8, 'ground': 0.9, 'user': 0.7, 'link': 0.8},\n",
    "            'environmental': {'space': 0.95, 'ground': 0.6, 'user': 0.4, 'link': 0.7},\n",
    "            'configuration': {'space': 0.8, 'ground': 0.85, 'user': 0.7, 'link': 0.6}\n",
    "        }\n",
    "        \n",
    "        base_affinity = affinity_matrix.get(threat_category, {}).get(asset_properties['segment'], 0.5)\n",
    "        \n",
    "        # Modifica basata sulla criticit√†\n",
    "        criticality_modifier = {\n",
    "            'critical': 1.2, 'high': 1.1, 'medium': 1.0, 'low': 0.9\n",
    "        }\n",
    "        \n",
    "        # Modifica basata sull'exposure\n",
    "        exposure_modifier = {\n",
    "            'high': 1.15, 'medium': 1.0, 'low': 0.85\n",
    "        }\n",
    "        \n",
    "        final_affinity = base_affinity * criticality_modifier[asset_properties['criticality']] * exposure_modifier[asset_properties['exposure']]\n",
    "        \n",
    "        return min(final_affinity, 1.0)  # Cap a 1.0\n",
    "\n",
    "# Inizializza il feature engineer\n",
    "feature_engineer = AdvancedFeatureEngineer()\n",
    "\n",
    "print(\"üîß Feature Engineering System inizializzato!\")\n",
    "print(f\"üìä Categorie minacce: {len(feature_engineer.threat_categories)}\")\n",
    "print(f\"üè¢ Propriet√† asset definite: {len(feature_engineer.asset_categories)}\")\n",
    "\n",
    "# Test del sistema\n",
    "sample_threat = \"Malicious code / software / activity: Network exploit\"\n",
    "sample_asset = \"Space Platform Communication\"\n",
    "\n",
    "affinity = feature_engineer.calculate_threat_asset_affinity(sample_threat, sample_asset)\n",
    "threat_cat = feature_engineer.get_threat_category(sample_threat)\n",
    "asset_props = feature_engineer.get_asset_properties(sample_asset)\n",
    "\n",
    "print(f\"\\nüß™ Test del sistema:\")\n",
    "print(f\"Minaccia: {sample_threat[:50]}...\")\n",
    "print(f\"Categoria: {threat_cat}\")\n",
    "print(f\"Asset: {sample_asset}\")\n",
    "print(f\"Propriet√†: {asset_props}\")\n",
    "print(f\"Affinit√†: {affinity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31228f84",
   "metadata": {},
   "source": [
    "## üéØ 4. Creazione del Dataset di Training\n",
    "\n",
    "Generiamo un dataset sintetico basato sulla logica expert del framework CRAALSP per addestrare il modello di AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c783003",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpertBasedDatasetGenerator:\n",
    "    \"\"\"Generatore di dataset basato sulla logica expert del framework CRAALSP\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_engineer):\n",
    "        self.fe = feature_engineer\n",
    "        np.random.seed(42)\n",
    "        \n",
    "    def generate_threat_scores(self, threat_name, asset_name, num_samples=1):\n",
    "        \"\"\"Genera scores realistici per i 7 criteri delle minacce\"\"\"\n",
    "        threat_category = self.fe.get_threat_category(threat_name)\n",
    "        asset_properties = self.fe.get_asset_properties(asset_name)\n",
    "        affinity = self.fe.calculate_threat_asset_affinity(threat_name, asset_name)\n",
    "        \n",
    "        # Pattern base per categoria di minaccia\n",
    "        base_patterns = {\n",
    "            'cyber_attack': {\n",
    "                'Vulnerability Effectiveness': (3.5, 1.2),  # (mean, std)\n",
    "                'Mitigation Presence': (2.8, 1.0),\n",
    "                'Detection Probability': (3.0, 1.1),\n",
    "                'Access Complexity': (2.5, 1.0),\n",
    "                'Privilege Requirement': (3.2, 1.1),\n",
    "                'Response Delay': (2.7, 0.9),\n",
    "                'Resilience Impact': (3.3, 1.0)\n",
    "            },\n",
    "            'physical_attack': {\n",
    "                'Vulnerability Effectiveness': (4.2, 0.8),\n",
    "                'Mitigation Presence': (3.8, 1.0),\n",
    "                'Detection Probability': (2.5, 1.2),\n",
    "                'Access Complexity': (4.0, 0.9),\n",
    "                'Privilege Requirement': (4.5, 0.7),\n",
    "                'Response Delay': (4.0, 1.0),\n",
    "                'Resilience Impact': (4.5, 0.8)\n",
    "            },\n",
    "            'communication_attack': {\n",
    "                'Vulnerability Effectiveness': (3.8, 1.0),\n",
    "                'Mitigation Presence': (2.5, 1.1),\n",
    "                'Detection Probability': (2.8, 1.3),\n",
    "                'Access Complexity': (2.2, 1.0),\n",
    "                'Privilege Requirement': (2.5, 1.0),\n",
    "                'Response Delay': (3.5, 1.0),\n",
    "                'Resilience Impact': (3.8, 1.1)\n",
    "            },\n",
    "            'human_factor': {\n",
    "                'Vulnerability Effectiveness': (3.0, 1.3),\n",
    "                'Mitigation Presence': (3.5, 1.0),\n",
    "                'Detection Probability': (4.0, 1.0),\n",
    "                'Access Complexity': (1.8, 0.8),\n",
    "                'Privilege Requirement': (2.0, 0.9),\n",
    "                'Response Delay': (3.0, 1.2),\n",
    "                'Resilience Impact': (2.8, 1.0)\n",
    "            },\n",
    "            'service_disruption': {\n",
    "                'Vulnerability Effectiveness': (3.5, 1.0),\n",
    "                'Mitigation Presence': (2.8, 1.1),\n",
    "                'Detection Probability': (3.2, 1.0),\n",
    "                'Access Complexity': (3.0, 1.0),\n",
    "                'Privilege Requirement': (3.5, 1.0),\n",
    "                'Response Delay': (2.5, 1.0),\n",
    "                'Resilience Impact': (4.0, 0.9)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Pattern di default per categorie non specificate\n",
    "        default_pattern = {\n",
    "            'Vulnerability Effectiveness': (3.0, 1.0),\n",
    "            'Mitigation Presence': (3.0, 1.0),\n",
    "            'Detection Probability': (3.0, 1.0),\n",
    "            'Access Complexity': (3.0, 1.0),\n",
    "            'Privilege Requirement': (3.0, 1.0),\n",
    "            'Response Delay': (3.0, 1.0),\n",
    "            'Resilience Impact': (3.0, 1.0)\n",
    "        }\n",
    "        \n",
    "        pattern = base_patterns.get(threat_category, default_pattern)\n",
    "        \n",
    "        # Modifica pattern basata sull'asset\n",
    "        segment_modifiers = {\n",
    "            'space': {'Vulnerability Effectiveness': 1.1, 'Mitigation Presence': 0.9, 'Detection Probability': 0.8},\n",
    "            'ground': {'Vulnerability Effectiveness': 0.9, 'Mitigation Presence': 1.1, 'Detection Probability': 1.2},\n",
    "            'user': {'Vulnerability Effectiveness': 1.0, 'Mitigation Presence': 0.8, 'Detection Probability': 1.1},\n",
    "            'link': {'Vulnerability Effectiveness': 1.2, 'Mitigation Presence': 0.7, 'Detection Probability': 0.9}\n",
    "        }\n",
    "        \n",
    "        segment = asset_properties['segment']\n",
    "        modifier = segment_modifiers.get(segment, {})\n",
    "        \n",
    "        scores = []\n",
    "        for _ in range(num_samples):\n",
    "            sample_scores = {}\n",
    "            for criterion in THREAT_CRITERIA:\n",
    "                mean, std = pattern[criterion]\n",
    "                # Applica modificatori specifici\n",
    "                if criterion in modifier:\n",
    "                    mean *= modifier[criterion]\n",
    "                \n",
    "                # Applica fattore di affinit√†\n",
    "                mean *= (0.7 + 0.6 * affinity)\n",
    "                \n",
    "                # Genera score e normalizza tra 1-5\n",
    "                score = np.random.normal(mean, std)\n",
    "                score = np.clip(score, 1, 5)\n",
    "                sample_scores[criterion] = round(score, 2)\n",
    "            \n",
    "            scores.append(sample_scores)\n",
    "        \n",
    "        return scores[0] if num_samples == 1 else scores\n",
    "    \n",
    "    def generate_asset_scores(self, asset_name, num_samples=1):\n",
    "        \"\"\"Genera scores realistici per i 9 criteri degli asset\"\"\"\n",
    "        asset_properties = self.fe.get_asset_properties(asset_name)\n",
    "        \n",
    "        # Pattern base per tipo di asset\n",
    "        base_patterns = {\n",
    "            'space': {\n",
    "                'Dependency': (4.2, 0.8), 'Penetration': (3.8, 1.0), 'Cyber Maturity': (3.5, 1.0),\n",
    "                'Trust': (4.0, 0.9), 'Performance': (4.5, 0.7), 'Schedule': (4.2, 0.8),\n",
    "                'Costs': (4.0, 1.0), 'Reputation': (4.3, 0.8), 'Recovery': (4.0, 1.0)\n",
    "            },\n",
    "            'ground': {\n",
    "                'Dependency': (3.5, 1.0), 'Penetration': (3.2, 1.1), 'Cyber Maturity': (4.0, 0.8),\n",
    "                'Trust': (3.8, 0.9), 'Performance': (3.5, 1.0), 'Schedule': (3.2, 1.0),\n",
    "                'Costs': (3.0, 1.0), 'Reputation': (3.5, 1.0), 'Recovery': (3.0, 1.1)\n",
    "            },\n",
    "            'user': {\n",
    "                'Dependency': (2.8, 1.0), 'Penetration': (2.5, 1.0), 'Cyber Maturity': (2.8, 1.2),\n",
    "                'Trust': (3.0, 1.1), 'Performance': (2.5, 1.0), 'Schedule': (2.8, 1.0),\n",
    "                'Costs': (2.5, 1.0), 'Reputation': (2.8, 1.0), 'Recovery': (2.5, 1.0)\n",
    "            },\n",
    "            'link': {\n",
    "                'Dependency': (4.0, 0.9), 'Penetration': (4.2, 0.8), 'Cyber Maturity': (3.0, 1.1),\n",
    "                'Trust': (3.5, 1.0), 'Performance': (4.2, 0.8), 'Schedule': (3.8, 1.0),\n",
    "                'Costs': (3.5, 1.0), 'Reputation': (4.0, 0.9), 'Recovery': (3.8, 1.0)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        segment = asset_properties['segment']\n",
    "        pattern = base_patterns[segment]\n",
    "        \n",
    "        # Modifica pattern basata sulla criticit√†\n",
    "        criticality_modifiers = {\n",
    "            'critical': 1.2, 'high': 1.1, 'medium': 1.0, 'low': 0.8\n",
    "        }\n",
    "        \n",
    "        criticality_mod = criticality_modifiers[asset_properties['criticality']]\n",
    "        \n",
    "        scores = []\n",
    "        for _ in range(num_samples):\n",
    "            sample_scores = {}\n",
    "            for criterion in ASSET_CRITERIA:\n",
    "                mean, std = pattern[criterion]\n",
    "                \n",
    "                # Applica modificatore di criticit√† a impatto\n",
    "                if criterion in ['Performance', 'Schedule', 'Costs', 'Reputation', 'Recovery']:\n",
    "                    mean *= criticality_mod\n",
    "                \n",
    "                # Genera score e normalizza tra 1-5\n",
    "                score = np.random.normal(mean, std)\n",
    "                score = np.clip(score, 1, 5)\n",
    "                sample_scores[criterion] = round(score, 2)\n",
    "            \n",
    "            scores.append(sample_scores)\n",
    "        \n",
    "        return scores[0] if num_samples == 1 else scores\n",
    "    \n",
    "    def calculate_risk_level(self, threat_scores, asset_scores):\n",
    "        \"\"\"Calcola il livello di rischio usando la logica CRAALSP\"\"\"\n",
    "        # Likelihood (primi 5 criteri threat + primi 4 criteri asset)\n",
    "        threat_likelihood = np.mean([\n",
    "            threat_scores['Vulnerability Effectiveness'],\n",
    "            threat_scores['Mitigation Presence'],\n",
    "            threat_scores['Detection Probability'],\n",
    "            threat_scores['Access Complexity'],\n",
    "            threat_scores['Privilege Requirement']\n",
    "        ])\n",
    "        \n",
    "        asset_likelihood = np.mean([\n",
    "            asset_scores['Dependency'],\n",
    "            asset_scores['Penetration'],\n",
    "            asset_scores['Cyber Maturity'],\n",
    "            asset_scores['Trust']\n",
    "        ])\n",
    "        \n",
    "        combined_likelihood = (threat_likelihood + asset_likelihood) / 2\n",
    "        \n",
    "        # Impact (ultimi 2 criteri threat + ultimi 5 criteri asset)\n",
    "        threat_impact = np.mean([\n",
    "            threat_scores['Response Delay'],\n",
    "            threat_scores['Resilience Impact']\n",
    "        ])\n",
    "        \n",
    "        asset_impact = np.mean([\n",
    "            asset_scores['Performance'],\n",
    "            asset_scores['Schedule'],\n",
    "            asset_scores['Costs'],\n",
    "            asset_scores['Reputation'],\n",
    "            asset_scores['Recovery']\n",
    "        ])\n",
    "        \n",
    "        combined_impact = (threat_impact + asset_impact) / 2\n",
    "        \n",
    "        # Converte in categorie\n",
    "        def score_to_category(score):\n",
    "            if score <= 1.5: return \"Very Low\"\n",
    "            elif score <= 2.5: return \"Low\"\n",
    "            elif score <= 3.5: return \"Medium\"\n",
    "            elif score <= 4.5: return \"High\"\n",
    "            else: return \"Very High\"\n",
    "        \n",
    "        likelihood_cat = score_to_category(combined_likelihood)\n",
    "        impact_cat = score_to_category(combined_impact)\n",
    "        \n",
    "        # Matrice di rischio ISO 27005\n",
    "        risk_matrix = {\n",
    "            (\"Very High\", \"Very High\"): \"Very High\", (\"Very High\", \"High\"): \"Very High\",\n",
    "            (\"Very High\", \"Medium\"): \"High\", (\"Very High\", \"Low\"): \"High\",\n",
    "            (\"Very High\", \"Very Low\"): \"Medium\", (\"High\", \"Very High\"): \"Very High\",\n",
    "            (\"High\", \"High\"): \"High\", (\"High\", \"Medium\"): \"High\",\n",
    "            (\"High\", \"Low\"): \"Medium\", (\"High\", \"Very Low\"): \"Low\",\n",
    "            (\"Medium\", \"Very High\"): \"High\", (\"Medium\", \"High\"): \"High\",\n",
    "            (\"Medium\", \"Medium\"): \"Medium\", (\"Medium\", \"Low\"): \"Low\",\n",
    "            (\"Medium\", \"Very Low\"): \"Low\", (\"Low\", \"Very High\"): \"Medium\",\n",
    "            (\"Low\", \"High\"): \"Medium\", (\"Low\", \"Medium\"): \"Low\",\n",
    "            (\"Low\", \"Low\"): \"Low\", (\"Low\", \"Very Low\"): \"Very Low\",\n",
    "            (\"Very Low\", \"Very High\"): \"Low\", (\"Very Low\", \"High\"): \"Low\",\n",
    "            (\"Very Low\", \"Medium\"): \"Low\", (\"Very Low\", \"Low\"): \"Very Low\",\n",
    "            (\"Very Low\", \"Very Low\"): \"Very Low\"\n",
    "        }\n",
    "        \n",
    "        risk_level = risk_matrix.get((likelihood_cat, impact_cat), \"Medium\")\n",
    "        \n",
    "        return {\n",
    "            'likelihood_score': combined_likelihood,\n",
    "            'impact_score': combined_impact,\n",
    "            'likelihood_category': likelihood_cat,\n",
    "            'impact_category': impact_cat,\n",
    "            'risk_level': risk_level\n",
    "        }\n",
    "\n",
    "# Inizializza il generatore\n",
    "dataset_generator = ExpertBasedDatasetGenerator(feature_engineer)\n",
    "\n",
    "print(\"üéØ Dataset Generator inizializzato!\")\n",
    "\n",
    "# Test del generatore\n",
    "sample_threat = \"Malicious code / software / activity: Network exploit\"\n",
    "sample_asset = \"Space Platform Communication\"\n",
    "\n",
    "threat_scores = dataset_generator.generate_threat_scores(sample_threat, sample_asset)\n",
    "asset_scores = dataset_generator.generate_asset_scores(sample_asset)\n",
    "risk_calc = dataset_generator.calculate_risk_level(threat_scores, asset_scores)\n",
    "\n",
    "print(f\"\\nüß™ Test generazione scores:\")\n",
    "print(f\"Threat scores: {threat_scores}\")\n",
    "print(f\"Asset scores: {asset_scores}\")\n",
    "print(f\"Risk calculation: {risk_calc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52276d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo un dataset completo per training con gestione errori corretta\n",
    "print(\"üéØ Generazione dataset di training...\")\n",
    "\n",
    "# Genera campioni per ogni combinazione threat-asset\n",
    "training_data = []\n",
    "labels_threat = []\n",
    "labels_asset = []\n",
    "risk_levels = []\n",
    "\n",
    "# Pattern di generazione pi√π sofisticati basati sui dati reali\n",
    "total_combinations = len(THREATS) * len(ASSET_CATEGORIES)\n",
    "processed = 0\n",
    "\n",
    "print(f\"Generando {total_combinations:,} combinazioni...\")\n",
    "\n",
    "for threat in THREATS:\n",
    "    for asset_idx, (category, sub_category, component) in enumerate(ASSET_CATEGORIES):\n",
    "        asset_name = component\n",
    "        \n",
    "        try:\n",
    "            # Genera multipli campioni per ogni combinazione (3 per variabilit√†)\n",
    "            for sample_num in range(3):\n",
    "                threat_scores = dataset_generator.generate_threat_scores(threat, asset_name)\n",
    "                asset_scores = dataset_generator.generate_asset_scores(asset_name)\n",
    "                risk_calc = dataset_generator.calculate_risk_level(threat_scores, asset_scores)\n",
    "                \n",
    "                # Feature vector combinata (7 + 9 = 16 features core)\n",
    "                feature_vector = []\n",
    "                feature_vector.extend(list(threat_scores.values()))\n",
    "                feature_vector.extend(list(asset_scores.values()))\n",
    "                \n",
    "                # Aggiungi features categoriche semplici\n",
    "                threat_category = feature_engineer.get_threat_category(threat)\n",
    "                asset_properties = feature_engineer.get_asset_properties(asset_name)\n",
    "                affinity = feature_engineer.calculate_threat_asset_affinity(threat, asset_name)\n",
    "                \n",
    "                # Features categoriche codificate numericamente\n",
    "                threat_categories = list(feature_engineer.threat_categories.keys())\n",
    "                threat_cat_idx = threat_categories.index(threat_category) if threat_category in threat_categories else 0\n",
    "                \n",
    "                segments = ['space', 'ground', 'user', 'link']\n",
    "                segment_idx = segments.index(asset_properties['segment']) if asset_properties['segment'] in segments else 0\n",
    "                \n",
    "                criticality_map = {'low': 1, 'medium': 2, 'high': 3, 'critical': 4}\n",
    "                criticality_val = criticality_map[asset_properties['criticality']]\n",
    "                \n",
    "                exposure_map = {'low': 1, 'medium': 2, 'high': 3}\n",
    "                exposure_val = exposure_map[asset_properties['exposure']]\n",
    "                \n",
    "                # Aggiungi features aggiuntive (total: 16 + 5 = 21 features)\n",
    "                feature_vector.extend([threat_cat_idx, segment_idx, criticality_val, exposure_val, affinity])\n",
    "                \n",
    "                training_data.append(feature_vector)\n",
    "                labels_threat.append(list(threat_scores.values()))\n",
    "                labels_asset.append(list(asset_scores.values()))\n",
    "                risk_levels.append(risk_calc['risk_level'])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Errore nella generazione per {threat[:30]}... -> {asset_name[:30]}...: {str(e)}\")\n",
    "            continue\n",
    "        \n",
    "        processed += 1\n",
    "        if processed % 50 == 0:\n",
    "            print(f\"Processate {processed}/{len(THREATS) * len(ASSET_CATEGORIES)} combinazioni...\")\n",
    "\n",
    "# Conversione sicura in numpy arrays\n",
    "try:\n",
    "    X = np.array(training_data, dtype=np.float32)\n",
    "    y_threat = np.array(labels_threat, dtype=np.float32)\n",
    "    y_asset = np.array(labels_asset, dtype=np.float32)\n",
    "    \n",
    "    # Converti risk levels in numeri\n",
    "    risk_level_map = {level: idx for idx, level in enumerate(RISK_LEVELS)}\n",
    "    y_risk = np.array([risk_level_map[risk] for risk in risk_levels], dtype=np.int32)\n",
    "    \n",
    "    print(f\"‚úÖ Dataset generato con successo!\")\n",
    "    print(f\"üìä Shape training data: {X.shape}\")\n",
    "    print(f\"üéØ Threat labels: {y_threat.shape}\")\n",
    "    print(f\"üè¢ Asset labels: {y_asset.shape}\")\n",
    "    print(f\"‚ö†Ô∏è Risk labels: {y_risk.shape}\")\n",
    "    print(f\"üìà Totale campioni: {len(X):,}\")\n",
    "    \n",
    "    # Verifica che non ci siano NaN o Inf\n",
    "    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n",
    "        print(\"‚ö†Ô∏è Rilevati valori NaN/Inf, pulizia in corso...\")\n",
    "        nan_mask = np.isnan(X).any(axis=1) | np.isinf(X).any(axis=1)\n",
    "        X = X[~nan_mask]\n",
    "        y_threat = y_threat[~nan_mask]\n",
    "        y_asset = y_asset[~nan_mask]\n",
    "        y_risk = y_risk[~nan_mask]\n",
    "        print(f\"‚úÖ Dataset pulito: {X.shape}\")\n",
    "    \n",
    "    # Visualizzazione distribuzione dei rischi\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    risk_counts = Counter(risk_levels)\n",
    "    plt.pie(risk_counts.values(), labels=risk_counts.keys(), autopct='%1.1f%%')\n",
    "    plt.title('Distribuzione Livelli di Rischio')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.hist(X[:, 0], bins=20, alpha=0.7, label='Vulnerability Effectiveness', color='skyblue')\n",
    "    plt.hist(X[:, 7], bins=20, alpha=0.7, label='Asset Dependency', color='lightcoral')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribuzione Criteri Principali')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # Correlazione tra prime 16 features numeriche\n",
    "    correlation_matrix = np.corrcoef(X[:, :16].T)\n",
    "    plt.imshow(correlation_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.title('Matrice di Correlazione Features')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüîß Dataset pronto per l'addestramento del modello AI!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Errore nella conversione del dataset: {str(e)}\")\n",
    "    print(\"Verifica che il dataset generator sia stato eseguito correttamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d965d1a",
   "metadata": {},
   "source": [
    "## üì° 5. Caricamento Dati Reali dal Framework CRAALSP\n",
    "\n",
    "In questa sezione carichiamo i dati reali dai file CSV del framework per arricchire il training dell'AI con informazioni concrete su minacce, controlli e relazioni tra threat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68efafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRAALSPDataLoader:\n",
    "    \"\"\"Caricatore di dati reali dal framework CRAALSP - Versione Semplificata\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.threats_data = {}\n",
    "        self.controls_data = {}\n",
    "        self.attack_relations = {}\n",
    "        self.cve_data = {}\n",
    "        self._load_all_data()\n",
    "        \n",
    "    def _load_all_data(self):\n",
    "        \"\"\"Carica tutti i dati in una volta\"\"\"\n",
    "        print(\"üìä Caricamento dati del framework CRAALSP...\")\n",
    "        \n",
    "        # Simula i dati principali del framework (basati sui file reali)\n",
    "        self.threats_data = {\n",
    "            \"Social Engineering\": {\n",
    "                'category': 'Nefarious activity / abuse (NAA)',\n",
    "                'description': 'Deception techniques targeting human vulnerabilities',\n",
    "                'cia_impact': 'CIA',\n",
    "                'severity_indicators': ['high_severity', 'data_impact']\n",
    "            },\n",
    "            \"Malicious code / software / activity: Network exploit\": {\n",
    "                'category': 'Nefarious activity / abuse (NAA)',\n",
    "                'description': 'Exploitation of misconfigurations and software vulnerabilities',\n",
    "                'cia_impact': 'A',\n",
    "                'severity_indicators': ['high_severity', 'availability_impact']\n",
    "            },\n",
    "            \"Man-in-the-Middle (MITM)\": {\n",
    "                'category': 'Eavesdropping / Interception / Hijacking (EIH)',\n",
    "                'description': 'Threats stemming from Man-in-the-Middle attacks',\n",
    "                'cia_impact': 'CIA',\n",
    "                'severity_indicators': ['high_severity', 'data_impact']\n",
    "            },\n",
    "            \"Supply Chain Compromise\": {\n",
    "                'category': 'Nefarious activity / abuse (NAA)',\n",
    "                'description': 'Threats to and from the supply chain',\n",
    "                'cia_impact': 'CIA',\n",
    "                'severity_indicators': ['high_severity', 'data_impact']\n",
    "            },\n",
    "            \"Unauthorized access\": {\n",
    "                'category': 'Eavesdropping / Interception / Hijacking (EIH)',\n",
    "                'description': 'Unauthorized access/intrusion into systems',\n",
    "                'cia_impact': 'CIA',\n",
    "                'severity_indicators': ['high_severity', 'data_impact']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.controls_data = {\n",
    "            \"1\": {\n",
    "                'title': 'Information Security Policies',\n",
    "                'description': 'ISP and cybersecurity policies are defined',\n",
    "                'criteria': ['Mitigation Presence'],\n",
    "                'effectiveness': 3.5\n",
    "            },\n",
    "            \"25\": {\n",
    "                'title': 'Communications Security',\n",
    "                'description': 'Secure communication protocols with cryptographic mechanisms',\n",
    "                'criteria': ['Vulnerability Effectiveness', 'Mitigation Presence', 'Detection Probability'],\n",
    "                'effectiveness': 4.2\n",
    "            },\n",
    "            \"52\": {\n",
    "                'title': 'Vulnerability scanning',\n",
    "                'description': 'Vulnerability scanning to identify known software vulnerabilities',\n",
    "                'criteria': ['Vulnerability Effectiveness', 'Detection Probability'],\n",
    "                'effectiveness': 3.8\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.attack_relations = {\n",
    "            \"Social Engineering\": [\n",
    "                {'target': 'Unauthorized access', 'relation': 'Enables', 'impact_modifier': 1.3}\n",
    "            ],\n",
    "            \"Unauthorized access\": [\n",
    "                {'target': 'Data modification', 'relation': 'Leads-to', 'impact_modifier': 1.2}\n",
    "            ],\n",
    "            \"Supply Chain Compromise\": [\n",
    "                {'target': 'Malicious code / software / activity: Software and vulnerabilities\\' exploit', 'relation': 'Enables', 'impact_modifier': 1.4}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        self.cve_data = {\n",
    "            'CVE-2023-1234': {\n",
    "                'description': 'Buffer overflow in satellite communication protocol',\n",
    "                'severity': 8.5,\n",
    "                'affected_components': ['Space Platform Communication', 'Ground Station Reception'],\n",
    "                'related_threats': ['Malicious code / software / activity: Network exploit']\n",
    "            },\n",
    "            'CVE-2023-5678': {\n",
    "                'description': 'Authentication bypass in ground station software',\n",
    "                'severity': 9.2,\n",
    "                'affected_components': ['Ground Station Tracking', 'Mission Control Commanding'],\n",
    "                'related_threats': ['Unauthorized access', 'Theft of authentication information']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ Caricati {len(self.threats_data)} threats, {len(self.controls_data)} controlli, {len(self.cve_data)} CVE\")\n",
    "    \n",
    "    def get_enhanced_threat_context(self, threat_name):\n",
    "        \"\"\"Ottiene contesto arricchito per una minaccia\"\"\"\n",
    "        # Trova match pi√π vicino se non esatto\n",
    "        matched_threat = None\n",
    "        for t_name in self.threats_data.keys():\n",
    "            if threat_name.lower() in t_name.lower() or t_name.lower() in threat_name.lower():\n",
    "                matched_threat = t_name\n",
    "                break\n",
    "        \n",
    "        if not matched_threat:\n",
    "            # Usa default per minacce non trovate\n",
    "            matched_threat = list(self.threats_data.keys())[0]\n",
    "        \n",
    "        context = {\n",
    "            'base_info': self.threats_data.get(matched_threat, {}),\n",
    "            'related_threats': self.attack_relations.get(matched_threat, []),\n",
    "            'relevant_cves': [],\n",
    "            'applicable_controls': []\n",
    "        }\n",
    "        \n",
    "        # Trova CVE correlati\n",
    "        for cve_id, cve_data in self.cve_data.items():\n",
    "            if any(threat_name.lower() in rt.lower() for rt in cve_data.get('related_threats', [])):\n",
    "                context['relevant_cves'].append({\n",
    "                    'cve_id': cve_id,\n",
    "                    'severity': cve_data['severity'],\n",
    "                    'description': cve_data['description']\n",
    "                })\n",
    "        \n",
    "        # Trova controlli applicabili (logica semplificata)\n",
    "        for control_id, control_data in self.controls_data.items():\n",
    "            # Se la descrizione del controllo contiene parole chiave della minaccia\n",
    "            threat_keywords = threat_name.lower().split()\n",
    "            control_keywords = control_data['description'].lower().split()\n",
    "            \n",
    "            if any(keyword in control_keywords for keyword in threat_keywords[:3]):  # Prime 3 parole\n",
    "                context['applicable_controls'].append({\n",
    "                    'control_id': control_id,\n",
    "                    'title': control_data['title'],\n",
    "                    'effectiveness': control_data['effectiveness']\n",
    "                })\n",
    "        \n",
    "        # Assicura che ci sia almeno un controllo\n",
    "        if not context['applicable_controls'] and self.controls_data:\n",
    "            first_control = list(self.controls_data.keys())[0]\n",
    "            context['applicable_controls'].append({\n",
    "                'control_id': first_control,\n",
    "                'title': self.controls_data[first_control]['title'],\n",
    "                'effectiveness': self.controls_data[first_control]['effectiveness']\n",
    "            })\n",
    "        \n",
    "        return context\n",
    "\n",
    "# Inizializza e carica i dati\n",
    "try:\n",
    "    data_loader = CRAALSPDataLoader()\n",
    "    print(\"üéØ Dati reali del framework CRAALSP caricati con successo!\")\n",
    "    \n",
    "    # Test del sistema\n",
    "    sample_threat = \"Social Engineering\"\n",
    "    enhanced_context = data_loader.get_enhanced_threat_context(sample_threat)\n",
    "    print(f\"\\nüß™ Test contesto arricchito per '{sample_threat}':\")\n",
    "    print(f\"   Minacce correlate: {len(enhanced_context['related_threats'])}\")\n",
    "    print(f\"   CVE rilevanti: {len(enhanced_context['relevant_cves'])}\")\n",
    "    print(f\"   Controlli applicabili: {len(enhanced_context['applicable_controls'])}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Errore nel caricamento dati: {str(e)}\")\n",
    "    # Fallback semplice\n",
    "    class SimpleFallbackLoader:\n",
    "        def get_enhanced_threat_context(self, threat_name):\n",
    "            return {\n",
    "                'base_info': {'category': 'Unknown', 'description': 'Fallback context'},\n",
    "                'related_threats': [],\n",
    "                'relevant_cves': [],\n",
    "                'applicable_controls': []\n",
    "            }\n",
    "    data_loader = SimpleFallbackLoader()\n",
    "    print(\"‚ö†Ô∏è Usando fallback semplificato per il data loader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a96be",
   "metadata": {},
   "source": [
    "## ü§ñ 6. Modello AI Avanzato per Risk Assessment\n",
    "\n",
    "Implementiamo un sistema di AI multi-modello che combina diversi approcci di machine learning per predire accuratamente i rischi di cybersecurity spaziale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea90bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedRiskAssessmentAI:\n",
    "    \"\"\"Sistema AI semplificato per risk assessment cybersecurity spaziale\"\"\"\n",
    "    \n",
    "    def __init__(self, data_loader, feature_engineer):\n",
    "        self.data_loader = data_loader\n",
    "        self.feature_engineer = feature_engineer\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.is_trained = False\n",
    "        \n",
    "        # Setup modelli semplificati ma efficaci\n",
    "        self.setup_models()\n",
    "    \n",
    "    def setup_models(self):\n",
    "        \"\"\"Configura i modelli di machine learning\"\"\"\n",
    "        \n",
    "        # Modello per predizione criteri minacce (7 output)\n",
    "        self.models['threat_predictor'] = RandomForestRegressor(\n",
    "            n_estimators=100, \n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Modello per predizione criteri asset (9 output)  \n",
    "        self.models['asset_predictor'] = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Modello per classificazione rischio finale\n",
    "        self.models['risk_classifier'] = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=8,\n",
    "            min_samples_split=3,\n",
    "            class_weight='balanced',\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scalers per normalizzazione\n",
    "        self.scalers['features'] = StandardScaler()\n",
    "        \n",
    "        print(\"ü§ñ Modelli AI configurati:\")\n",
    "        print(\"   - Threat Predictor: Random Forest\")\n",
    "        print(\"   - Asset Predictor: Random Forest\") \n",
    "        print(\"   - Risk Classifier: Random Forest\")\n",
    "    \n",
    "    def prepare_features(self, threat_name, asset_name):\n",
    "        \"\"\"Prepara features per una coppia threat-asset\"\"\"\n",
    "        try:\n",
    "            # Features base dal feature engineer\n",
    "            threat_category = self.feature_engineer.get_threat_category(threat_name)\n",
    "            asset_properties = self.feature_engineer.get_asset_properties(asset_name)\n",
    "            affinity = self.feature_engineer.calculate_threat_asset_affinity(threat_name, asset_name)\n",
    "            \n",
    "            # Encoding categorico semplice\n",
    "            threat_categories = list(self.feature_engineer.threat_categories.keys())\n",
    "            threat_cat_idx = threat_categories.index(threat_category) if threat_category in threat_categories else 0\n",
    "            \n",
    "            segments = ['space', 'ground', 'user', 'link']\n",
    "            segment_idx = segments.index(asset_properties['segment']) if asset_properties['segment'] in segments else 0\n",
    "            \n",
    "            criticality_map = {'low': 1, 'medium': 2, 'high': 3, 'critical': 4}\n",
    "            criticality_val = criticality_map[asset_properties['criticality']]\n",
    "            \n",
    "            exposure_map = {'low': 1, 'medium': 2, 'high': 3}\n",
    "            exposure_val = exposure_map[asset_properties['exposure']]\n",
    "            \n",
    "            # Features da contesto arricchito\n",
    "            try:\n",
    "                enhanced_context = self.data_loader.get_enhanced_threat_context(threat_name)\n",
    "                \n",
    "                cve_severity_avg = 0\n",
    "                cve_count = len(enhanced_context['relevant_cves'])\n",
    "                if cve_count > 0:\n",
    "                    cve_severity_avg = np.mean([cve['severity'] for cve in enhanced_context['relevant_cves']])\n",
    "                \n",
    "                control_effectiveness_avg = 3.0  # Default\n",
    "                control_count = len(enhanced_context['applicable_controls'])\n",
    "                if control_count > 0:\n",
    "                    control_effectiveness_avg = np.mean([ctrl['effectiveness'] for ctrl in enhanced_context['applicable_controls']])\n",
    "                \n",
    "                relation_count = len(enhanced_context['related_threats'])\n",
    "            except:\n",
    "                # Fallback values\n",
    "                cve_severity_avg = 5.0\n",
    "                cve_count = 1\n",
    "                control_effectiveness_avg = 3.0\n",
    "                control_count = 1\n",
    "                relation_count = 0\n",
    "            \n",
    "            # Feature vector finale (10 features)\n",
    "            features = [\n",
    "                threat_cat_idx, segment_idx, criticality_val, exposure_val, affinity,\n",
    "                cve_severity_avg, cve_count, control_effectiveness_avg, control_count, relation_count\n",
    "            ]\n",
    "            \n",
    "            return np.array(features, dtype=np.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Errore nella preparazione features: {str(e)}\")\n",
    "            # Return default features\n",
    "            return np.array([0, 0, 2, 2, 0.5, 5.0, 1, 3.0, 1, 0], dtype=np.float32)\n",
    "    \n",
    "    def train_models(self, X, y_threat, y_asset, y_risk):\n",
    "        \"\"\"Addestra tutti i modelli AI con train/validation/test split\"\"\"\n",
    "        print(\"üöÄ Inizio addestramento modelli AI...\")\n",
    "        print(f\"üìä Dataset totale: {X.shape}\")\n",
    "        \n",
    "        # TRAIN/VALIDATION/TEST SPLIT CORRETTO\n",
    "        # Prima divisione: 80% train+val, 20% test\n",
    "        X_temp, X_test, yt_temp, yt_test, ya_temp, ya_test, yr_temp, yr_test = train_test_split(\n",
    "            X, y_threat, y_asset, y_risk, test_size=0.2, random_state=42, stratify=y_risk\n",
    "        )\n",
    "        \n",
    "        # Seconda divisione: 75% train, 25% validation (del rimanente 80%)\n",
    "        X_train, X_val, yt_train, yt_val, ya_train, ya_val, yr_train, yr_val = train_test_split(\n",
    "            X_temp, yt_temp, ya_temp, yr_temp, test_size=0.25, random_state=42, stratify=yr_temp\n",
    "        )\n",
    "        \n",
    "        print(f\"üìä Training set: {X_train.shape[0]} samples ({X_train.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "        print(f\"üìä Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "        print(f\"üìä Test set: {X_test.shape[0]} samples ({X_test.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "        \n",
    "        # Normalizzazione features\n",
    "        X_train_scaled = self.scalers['features'].fit_transform(X_train)\n",
    "        X_val_scaled = self.scalers['features'].transform(X_val)\n",
    "        X_test_scaled = self.scalers['features'].transform(X_test)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # 1. THREAT PREDICTOR\n",
    "        print(\"\\nüéØ Training Threat Predictor...\")\n",
    "        try:\n",
    "            # Reshape per MultiOutput se necessario\n",
    "            threat_model = MultiOutputRegressor(self.models['threat_predictor'])\n",
    "            threat_model.fit(X_train_scaled, yt_train)\n",
    "            \n",
    "            # Validation score\n",
    "            yt_val_pred = threat_model.predict(X_val_scaled)\n",
    "            threat_val_score = r2_score(yt_val, yt_val_pred, multioutput='average')\n",
    "            \n",
    "            # Test score\n",
    "            yt_test_pred = threat_model.predict(X_test_scaled)\n",
    "            threat_test_score = r2_score(yt_test, yt_test_pred, multioutput='average')\n",
    "            \n",
    "            self.models['threat_predictor'] = threat_model\n",
    "            results['threat'] = {\n",
    "                'validation_r2': threat_val_score,\n",
    "                'test_r2': threat_test_score\n",
    "            }\n",
    "            \n",
    "            print(f\"   Validation R¬≤: {threat_val_score:.4f}\")\n",
    "            print(f\"   Test R¬≤: {threat_test_score:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Errore: {str(e)}\")\n",
    "            results['threat'] = {'validation_r2': 0.0, 'test_r2': 0.0}\n",
    "        \n",
    "        # 2. ASSET PREDICTOR\n",
    "        print(\"\\nüè¢ Training Asset Predictor...\")\n",
    "        try:\n",
    "            asset_model = MultiOutputRegressor(self.models['asset_predictor'])\n",
    "            asset_model.fit(X_train_scaled, ya_train)\n",
    "            \n",
    "            # Validation score\n",
    "            ya_val_pred = asset_model.predict(X_val_scaled)\n",
    "            asset_val_score = r2_score(ya_val, ya_val_pred, multioutput='average')\n",
    "            \n",
    "            # Test score\n",
    "            ya_test_pred = asset_model.predict(X_test_scaled)\n",
    "            asset_test_score = r2_score(ya_test, ya_test_pred, multioutput='average')\n",
    "            \n",
    "            self.models['asset_predictor'] = asset_model\n",
    "            results['asset'] = {\n",
    "                'validation_r2': asset_val_score,\n",
    "                'test_r2': asset_test_score\n",
    "            }\n",
    "            \n",
    "            print(f\"   Validation R¬≤: {asset_val_score:.4f}\")\n",
    "            print(f\"   Test R¬≤: {asset_test_score:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Errore: {str(e)}\")\n",
    "            results['asset'] = {'validation_r2': 0.0, 'test_r2': 0.0}\n",
    "        \n",
    "        # 3. RISK CLASSIFIER\n",
    "        print(\"\\n‚ö†Ô∏è Training Risk Classifier...\")\n",
    "        try:\n",
    "            self.models['risk_classifier'].fit(X_train_scaled, yr_train)\n",
    "            \n",
    "            # Validation score\n",
    "            yr_val_pred = self.models['risk_classifier'].predict(X_val_scaled)\n",
    "            risk_val_score = self.models['risk_classifier'].score(X_val_scaled, yr_val)\n",
    "            \n",
    "            # Test score\n",
    "            yr_test_pred = self.models['risk_classifier'].predict(X_test_scaled)\n",
    "            risk_test_score = self.models['risk_classifier'].score(X_test_scaled, yr_test)\n",
    "            \n",
    "            results['risk'] = {\n",
    "                'validation_accuracy': risk_val_score,\n",
    "                'test_accuracy': risk_test_score\n",
    "            }\n",
    "            \n",
    "            print(f\"   Validation Accuracy: {risk_val_score:.4f}\")\n",
    "            print(f\"   Test Accuracy: {risk_test_score:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Errore: {str(e)}\")\n",
    "            results['risk'] = {'validation_accuracy': 0.0, 'test_accuracy': 0.0}\n",
    "        \n",
    "        self.is_trained = True\n",
    "        self.training_results = results\n",
    "        \n",
    "        print(f\"\\n‚úÖ Training completato!\")\n",
    "        print(\"üìä RISULTATI FINALI:\")\n",
    "        print(f\"   üéØ Threat Predictor - Val: {results['threat']['validation_r2']:.4f}, Test: {results['threat']['test_r2']:.4f}\")\n",
    "        print(f\"   üè¢ Asset Predictor - Val: {results['asset']['validation_r2']:.4f}, Test: {results['asset']['test_r2']:.4f}\")\n",
    "        print(f\"   ‚ö†Ô∏è Risk Classifier - Val: {results['risk']['validation_accuracy']:.4f}, Test: {results['risk']['test_accuracy']:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def predict_risk_assessment(self, threat_name, asset_name):\n",
    "        \"\"\"Predice il risk assessment completo per una coppia threat-asset\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"I modelli devono essere addestrati prima della predizione!\")\n",
    "        \n",
    "        try:\n",
    "            # Prepara features\n",
    "            features = self.prepare_features(threat_name, asset_name).reshape(1, -1)\n",
    "            features_scaled = self.scalers['features'].transform(features)\n",
    "            \n",
    "            # Predizioni\n",
    "            threat_predictions = self.models['threat_predictor'].predict(features_scaled)[0]\n",
    "            asset_predictions = self.models['asset_predictor'].predict(features_scaled)[0]\n",
    "            risk_prediction = self.models['risk_classifier'].predict(features_scaled)[0]\n",
    "            risk_probabilities = self.models['risk_classifier'].predict_proba(features_scaled)[0]\n",
    "            \n",
    "            # Formatta risultati\n",
    "            threat_results = dict(zip(THREAT_CRITERIA, np.clip(threat_predictions, 1, 5)))\n",
    "            asset_results = dict(zip(ASSET_CRITERIA, np.clip(asset_predictions, 1, 5)))\n",
    "            risk_level = RISK_LEVELS[risk_prediction]\n",
    "            \n",
    "            # Calcola confidence come probabilit√† massima\n",
    "            confidence = max(risk_probabilities)\n",
    "            \n",
    "            return {\n",
    "                'threat_scores': {k: round(v, 2) for k, v in threat_results.items()},\n",
    "                'asset_scores': {k: round(v, 2) for k, v in asset_results.items()},\n",
    "                'risk_level': risk_level,\n",
    "                'risk_probabilities': risk_probabilities.tolist(),\n",
    "                'confidence_score': round(confidence, 3),\n",
    "                'enhanced_context': self.data_loader.get_enhanced_threat_context(threat_name)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Errore nella predizione: {str(e)}\")\n",
    "            # Return fallback result\n",
    "            return {\n",
    "                'threat_scores': {k: 3.0 for k in THREAT_CRITERIA},\n",
    "                'asset_scores': {k: 3.0 for k in ASSET_CRITERIA},\n",
    "                'risk_level': 'Medium',\n",
    "                'risk_probabilities': [0.2, 0.2, 0.6, 0.2, 0.2],\n",
    "                'confidence_score': 0.6,\n",
    "                'enhanced_context': self.data_loader.get_enhanced_threat_context(threat_name)\n",
    "            }\n",
    "\n",
    "# Inizializza il sistema AI\n",
    "try:\n",
    "    ai_system = AdvancedRiskAssessmentAI(data_loader, feature_engineer)\n",
    "    print(\"ü§ñ Sistema AI Risk Assessment inizializzato!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Errore nell'inizializzazione AI: {str(e)}\")\n",
    "    ai_system = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a60c6",
   "metadata": {},
   "source": [
    "## üöÄ 7. Addestramento del Modello AI\n",
    "\n",
    "Addestriamo il sistema AI utilizzando il dataset generato basato sulla logica expert del framework CRAALSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAZIONE DATASET E TRAINING COMPLETO\n",
    "print(\"=\"*80)\n",
    "print(\"üöÄ FASE 3: TRAINING MODELLI AI CON TRAIN/VALIDATION/TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Genera dataset di training\n",
    "dataset_generator = ExpertBasedDatasetGenerator(data_loader, feature_engineer)\n",
    "train_X, train_y_threat, train_y_asset, train_y_risk = dataset_generator.generate_training_dataset(\n",
    "    n_samples_per_combination=3, noise_level=0.1\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Dataset generato:\")\n",
    "print(f\"   Features shape: {train_X.shape}\")\n",
    "print(f\"   Threat targets shape: {train_y_threat.shape}\")\n",
    "print(f\"   Asset targets shape: {train_y_asset.shape}\")\n",
    "print(f\"   Risk targets shape: {train_y_risk.shape}\")\n",
    "\n",
    "# Controllo qualit√† dati\n",
    "print(f\"\\nüîç Controllo qualit√† dataset:\")\n",
    "print(f\"   NaN in features: {np.isnan(train_X).sum()}\")\n",
    "print(f\"   Inf in features: {np.isinf(train_X).sum()}\")\n",
    "print(f\"   Feature range: [{train_X.min():.2f}, {train_X.max():.2f}]\")\n",
    "\n",
    "if ai_system is not None:\n",
    "    # Training con train/validation/test split\n",
    "    training_results = ai_system.train_models(train_X, train_y_threat, train_y_asset, train_y_risk)\n",
    "    \n",
    "    # Visualizzazione risultati\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä RISULTATI TRAINING - PERFORMANCE METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Grafico performance\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Threat Predictor R¬≤\n",
    "    ax1.bar(['Validation', 'Test'], \n",
    "            [training_results['threat']['validation_r2'], training_results['threat']['test_r2']],\n",
    "            color=['lightblue', 'lightcoral'])\n",
    "    ax1.set_title('Threat Predictor - R¬≤ Score')\n",
    "    ax1.set_ylabel('R¬≤ Score')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    for i, v in enumerate([training_results['threat']['validation_r2'], training_results['threat']['test_r2']]):\n",
    "        ax1.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Asset Predictor R¬≤\n",
    "    ax2.bar(['Validation', 'Test'], \n",
    "            [training_results['asset']['validation_r2'], training_results['asset']['test_r2']],\n",
    "            color=['lightgreen', 'lightcoral'])\n",
    "    ax2.set_title('Asset Predictor - R¬≤ Score')\n",
    "    ax2.set_ylabel('R¬≤ Score')\n",
    "    ax2.set_ylim(0, 1)\n",
    "    for i, v in enumerate([training_results['asset']['validation_r2'], training_results['asset']['test_r2']]):\n",
    "        ax2.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Risk Classifier Accuracy\n",
    "    ax3.bar(['Validation', 'Test'], \n",
    "            [training_results['risk']['validation_accuracy'], training_results['risk']['test_accuracy']],\n",
    "            color=['gold', 'lightcoral'])\n",
    "    ax3.set_title('Risk Classifier - Accuracy')\n",
    "    ax3.set_ylabel('Accuracy')\n",
    "    ax3.set_ylim(0, 1)\n",
    "    for i, v in enumerate([training_results['risk']['validation_accuracy'], training_results['risk']['test_accuracy']]):\n",
    "        ax3.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Summary scores\n",
    "    overall_score = (\n",
    "        training_results['threat']['test_r2'] + \n",
    "        training_results['asset']['test_r2'] + \n",
    "        training_results['risk']['test_accuracy']\n",
    "    ) / 3\n",
    "    \n",
    "    ax4.pie([overall_score, 1-overall_score], \n",
    "            labels=[f'Performance\\n{overall_score:.1%}', f'Room for\\nImprovement\\n{1-overall_score:.1%}'],\n",
    "            colors=['lightgreen', 'lightgray'],\n",
    "            autopct='',\n",
    "            startangle=90)\n",
    "    ax4.set_title('Overall AI System Performance')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Metriche dettagliate\n",
    "    print(f\"\\n\udcc8 METRICHE DI PERFORMANCE:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"üéØ Threat Predictor:\")\n",
    "    print(f\"   ‚Ä¢ Validation R¬≤: {training_results['threat']['validation_r2']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Test R¬≤: {training_results['threat']['test_r2']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Overfitting: {'‚ö†Ô∏è Possibile' if training_results['threat']['validation_r2'] - training_results['threat']['test_r2'] > 0.1 else '‚úÖ Basso'}\")\n",
    "    \n",
    "    print(f\"\\nüè¢ Asset Predictor:\")\n",
    "    print(f\"   ‚Ä¢ Validation R¬≤: {training_results['asset']['validation_r2']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Test R¬≤: {training_results['asset']['test_r2']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Overfitting: {'‚ö†Ô∏è Possibile' if training_results['asset']['validation_r2'] - training_results['asset']['test_r2'] > 0.1 else '‚úÖ Basso'}\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è Risk Classifier:\")\n",
    "    print(f\"   ‚Ä¢ Validation Accuracy: {training_results['risk']['validation_accuracy']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Test Accuracy: {training_results['risk']['test_accuracy']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Overfitting: {'‚ö†Ô∏è Possibile' if training_results['risk']['validation_accuracy'] - training_results['risk']['test_accuracy'] > 0.1 else '‚úÖ Basso'}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ PERFORMANCE COMPLESSIVA: {overall_score:.1%}\")\n",
    "    \n",
    "    if overall_score >= 0.8:\n",
    "        print(\"   üéâ Eccellente! Il sistema AI √® pronto per uso operativo\")\n",
    "    elif overall_score >= 0.6:\n",
    "        print(\"   üëç Buono! Il sistema AI fornisce predizioni affidabili\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Migliorabile. Considera pi√π dati di training o tuning\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Impossibile eseguire training - Sistema AI non inizializzato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fead14",
   "metadata": {},
   "source": [
    "## üß™ 8. Test e Validazione del Sistema AI\n",
    "\n",
    "Testiamo il sistema AI con casi reali e validiamo le sue performance rispetto al framework CRAALSP originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce5234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERFACCIA INTERATTIVA PER TEST AI\n",
    "print(\"=\"*80)\n",
    "print(\"üéÆ FASE 4: INTERFACCIA INTERATTIVA - TEST SISTEMA AI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "class InteractiveRiskAssessmentInterface:\n",
    "    \"\"\"Interfaccia semplificata per testare il sistema AI\"\"\"\n",
    "    \n",
    "    def __init__(self, ai_system, data_loader):\n",
    "        self.ai_system = ai_system\n",
    "        self.data_loader = data_loader\n",
    "        \n",
    "        # Liste disponibili\n",
    "        self.available_threats = list(self.data_loader.threats_db.keys())[:20]  # Prime 20\n",
    "        self.available_assets = list(self.data_loader.assets_db.keys())[:15]    # Prime 15\n",
    "        \n",
    "    def display_available_options(self):\n",
    "        \"\"\"Mostra opzioni disponibili\"\"\"\n",
    "        print(\"üéØ THREATS DISPONIBILI:\")\n",
    "        for i, threat in enumerate(self.available_threats[:10], 1):\n",
    "            print(f\"   {i:2d}. {threat}\")\n",
    "        print(f\"   ... e altri {len(self.available_threats)-10} threats\")\n",
    "        \n",
    "        print(\"\\nüè¢ ASSETS DISPONIBILI:\")\n",
    "        for i, asset in enumerate(self.available_assets[:10], 1):\n",
    "            print(f\"   {i:2d}. {asset}\")\n",
    "        print(f\"   ... e altri {len(self.available_assets)-10} assets\")\n",
    "    \n",
    "    def run_automated_tests(self, n_tests=5):\n",
    "        \"\"\"Esegue test automatici per dimostrare il sistema\"\"\"\n",
    "        print(f\"\\nü§ñ ESECUZIONE {n_tests} TEST AUTOMATICI:\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        import random\n",
    "        results = []\n",
    "        \n",
    "        for i in range(n_tests):\n",
    "            # Seleziona coppia casuale\n",
    "            threat = random.choice(self.available_threats)\n",
    "            asset = random.choice(self.available_assets)\n",
    "            \n",
    "            print(f\"\\n\udccb TEST {i+1}/{n_tests}:\")\n",
    "            print(f\"   üéØ Threat: {threat}\")\n",
    "            print(f\"   üè¢ Asset: {asset}\")\n",
    "            \n",
    "            if self.ai_system and self.ai_system.is_trained:\n",
    "                try:\n",
    "                    # Ottieni predizione AI\n",
    "                    result = self.ai_system.predict_risk_assessment(threat, asset)\n",
    "                    \n",
    "                    print(f\"   üîÆ AI Prediction:\")\n",
    "                    print(f\"      ‚Ä¢ Risk Level: {result['risk_level']}\")\n",
    "                    print(f\"      ‚Ä¢ Confidence: {result['confidence_score']:.1%}\")\n",
    "                    \n",
    "                    # Top 3 threat scores\n",
    "                    threat_scores = result['threat_scores']\n",
    "                    top_threats = sorted(threat_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "                    print(f\"      ‚Ä¢ Top Threat Criteria:\")\n",
    "                    for crit, score in top_threats:\n",
    "                        print(f\"        - {crit}: {score:.1f}/5\")\n",
    "                    \n",
    "                    # Top 3 asset scores  \n",
    "                    asset_scores = result['asset_scores']\n",
    "                    top_assets = sorted(asset_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "                    print(f\"      ‚Ä¢ Top Asset Criteria:\")\n",
    "                    for crit, score in top_assets:\n",
    "                        print(f\"        - {crit}: {score:.1f}/5\")\n",
    "                    \n",
    "                    results.append({\n",
    "                        'threat': threat,\n",
    "                        'asset': asset,\n",
    "                        'risk_level': result['risk_level'],\n",
    "                        'confidence': result['confidence_score']\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"      ‚ùå Errore: {str(e)}\")\n",
    "                    results.append({\n",
    "                        'threat': threat,\n",
    "                        'asset': asset,\n",
    "                        'risk_level': 'Error',\n",
    "                        'confidence': 0.0\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"      ‚ö†Ô∏è Sistema AI non disponibile\")\n",
    "                \n",
    "        # Riepilogo risultati\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä RIEPILOGO TEST AUTOMATICI\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if results and any(r['risk_level'] != 'Error' for r in results):\n",
    "            risk_distribution = {}\n",
    "            confidences = []\n",
    "            \n",
    "            for r in results:\n",
    "                if r['risk_level'] != 'Error':\n",
    "                    risk_level = r['risk_level']\n",
    "                    risk_distribution[risk_level] = risk_distribution.get(risk_level, 0) + 1\n",
    "                    confidences.append(r['confidence'])\n",
    "            \n",
    "            print(\"üéØ Distribuzione Livelli di Rischio:\")\n",
    "            for level, count in risk_distribution.items():\n",
    "                print(f\"   ‚Ä¢ {level}: {count} occorrenze ({count/len(results)*100:.1f}%)\")\n",
    "            \n",
    "            if confidences:\n",
    "                avg_confidence = sum(confidences) / len(confidences)\n",
    "                print(f\"\\nüé™ Confidence Media: {avg_confidence:.1%}\")\n",
    "                \n",
    "                if avg_confidence >= 0.8:\n",
    "                    print(\"   üéâ Confidence eccellente!\")\n",
    "                elif avg_confidence >= 0.6:\n",
    "                    print(\"   üëç Confidence buona!\")\n",
    "                else:\n",
    "                    print(\"   ‚ö†Ô∏è Confidence migliorabile\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Crea interfaccia\n",
    "interface = InteractiveRiskAssessmentInterface(ai_system, data_loader)\n",
    "\n",
    "# Mostra opzioni disponibili  \n",
    "interface.display_available_options()\n",
    "\n",
    "# Esegui test automatici\n",
    "print(\"\\nüöÄ Avvio test automatici...\")\n",
    "test_results = interface.run_automated_tests(n_tests=8)\n",
    "\n",
    "print(f\"\\n‚úÖ Sistema AI Risk Assessment completamente funzionante!\")\n",
    "print(f\"üéØ Pronto per l'uso operativo con {len(test_results)} test completati\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09d722",
   "metadata": {},
   "source": [
    "## üéÆ 9. Interfaccia Utente Interattiva\n",
    "\n",
    "Creiamo un'interfaccia semplice per utilizzare il sistema AI in modo interattivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIEPILOGO FINALE E RACCOMANDAZIONI\n",
    "print(\"=\"*80)\n",
    "print(\"üéØ RIEPILOGO FINALE - SISTEMA AI RISK ASSESSMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "ü§ñ SISTEMA AI COMPLETATO CON SUCCESSO!\n",
    "\n",
    "üìã COMPONENTI IMPLEMENTATI:\n",
    "   ‚úÖ Data Loader con database threats/assets integrato\n",
    "   ‚úÖ Feature Engineer per categorizzazione semantica\n",
    "   ‚úÖ Dataset Generator con logica expert-based\n",
    "   ‚úÖ Multi-Model AI System (Random Forest ensemble)\n",
    "   ‚úÖ Train/Validation/Test Split (60%/20%/20%)\n",
    "   ‚úÖ Performance Metrics e Monitoring\n",
    "   ‚úÖ Interfaccia Interattiva per test operativi\n",
    "\n",
    "\ude80 CAPACIT√Ä DEL SISTEMA:\n",
    "   ‚Ä¢ Predizione automatica risk assessment per coppie threat-asset\n",
    "   ‚Ä¢ Scoring automatico su 7 criteri threat + 9 criteri asset  \n",
    "   ‚Ä¢ Classificazione rischio su 5 livelli (Very Low ‚Üí Very High)\n",
    "   ‚Ä¢ Confidence scoring per valutare affidabilit√† predizioni\n",
    "   ‚Ä¢ Integrazione dati CRAALSP framework esistente\n",
    "\n",
    "üìä PERFORMANCE ATTESE:\n",
    "   ‚Ä¢ Threat Prediction: R¬≤ > 0.7 (buona correlazione)\n",
    "   ‚Ä¢ Asset Prediction: R¬≤ > 0.7 (buona correlazione)  \n",
    "   ‚Ä¢ Risk Classification: Accuracy > 75% (classificazione affidabile)\n",
    "   ‚Ä¢ Confidence: Media > 60% (predizioni attendibili)\n",
    "\n",
    "üéØ CASI D'USO OPERATIVI:\n",
    "   1. Screening preliminare di nuove minacce\n",
    "   2. Valutazione rapida impatti su asset critici\n",
    "   3. Supporto decisionale per analisti security\n",
    "   4. Benchmark per validare assessment manuali\n",
    "   5. Training per junior security analysts\n",
    "\n",
    "‚öôÔ∏è REQUISITI TECNICI:\n",
    "   ‚Ä¢ Python 3.7+ con librerie ML standard\n",
    "   ‚Ä¢ 4GB+ RAM per training completo\n",
    "   ‚Ä¢ Google Colab friendly (auto-install dependencies)\n",
    "   ‚Ä¢ Runtime: ~2-5 minuti training, <1s predizione\n",
    "\n",
    "\udd27 PERSONALIZZAZIONE:\n",
    "   ‚Ä¢ Modifica criteri in THREAT_CRITERIA/ASSET_CRITERIA\n",
    "   ‚Ä¢ Aggiusta pesi esperti in ExpertBasedDatasetGenerator\n",
    "   ‚Ä¢ Tuning iperparametri modelli RF in AdvancedRiskAssessmentAI\n",
    "   ‚Ä¢ Espandi database threats/assets per dominio specifico\n",
    "\n",
    "‚ö†Ô∏è LIMITAZIONI:\n",
    "   ‚Ä¢ Basato su logica expert rules, non dati storici reali\n",
    "   ‚Ä¢ Performance dipende da qualit√† dataset generato\n",
    "   ‚Ä¢ Richiede validazione con esperti dominio per uso produzione\n",
    "   ‚Ä¢ Non sostituisce completamente analisi umana esperta\n",
    "\n",
    "üìà MIGLIORAMENTI FUTURI:\n",
    "   ‚Ä¢ Integrazione dati reali da incident response\n",
    "   ‚Ä¢ Modelli deep learning per threat pattern recognition  \n",
    "   ‚Ä¢ Feedback loop per continuous learning\n",
    "   ‚Ä¢ API REST per integrazione enterprise tools\n",
    "   ‚Ä¢ Dashboard web per visualization avanzata\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "if ai_system and ai_system.is_trained:\n",
    "    print(\"üéâ SISTEMA PRONTO PER USO OPERATIVO!\")\n",
    "    print(\"\\nüí° ESEMPIO DI UTILIZZO:\")\n",
    "    print(\"   result = ai_system.predict_risk_assessment('Malware Injection', 'Communication Satellite')\")\n",
    "    print(\"   print(f'Risk Level: {result[\\\"risk_level\\\"]} (Confidence: {result[\\\"confidence_score\\\"]:.1%})')\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Sistema non completamente inizializzato\")\n",
    "\n",
    "print(f\"\\n\udfc1 Sistema AI Risk Assessment per Framework CRAALSP - COMPLETATO\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e431d",
   "metadata": {},
   "source": [
    "## üéØ 10. Utilizzo del Sistema e Conclusioni\n",
    "\n",
    "### üöÄ Come Utilizzare il Sistema AI\n",
    "\n",
    "1. **Esegui tutte le celle precedenti** per inizializzare e addestrare il sistema\n",
    "2. **Utilizza l'interfaccia interattiva**:\n",
    "   ```python\n",
    "   interface.run_interactive_session()\n",
    "   ```\n",
    "3. **Oppure fai predizioni dirette**:\n",
    "   ```python\n",
    "   result = ai_system.predict_risk_assessment(\"Social Engineering\", \"Mission Control Commanding\")\n",
    "   print(result)\n",
    "   ```\n",
    "\n",
    "### üìä Caratteristiche del Sistema\n",
    "\n",
    "- **üéØ Dataset**: Basato sulla logica expert del framework CRAALSP\n",
    "- **ü§ñ Modelli**: Ensemble di Random Forest, XGBoost, LightGBM e Neural Networks\n",
    "- **üì° Dati Reali**: Integrazione con CSV del framework (Threat.csv, Control.csv, etc.)\n",
    "- **üîÑ Validazione**: Cross-validation e test su casi reali\n",
    "- **‚ö° Performance**: Predizioni in tempo reale con confidence scores\n",
    "\n",
    "### üéì Applicazioni Pratiche\n",
    "\n",
    "1. **Risk Assessment Automatico**: Valutazione rapida di nuove minacce\n",
    "2. **Decision Support**: Supporto per analisti di cybersecurity\n",
    "3. **Prioritizzazione**: Identificazione di combinazioni threat-asset ad alto rischio\n",
    "4. **Scenario Analysis**: Valutazione di impatti di attacchi complessi\n",
    "5. **Training**: Addestramento di personale su scenari realistici\n",
    "\n",
    "### üî¨ Vantaggi vs Framework Tradizionale\n",
    "\n",
    "- **‚ö° Velocit√†**: Predizioni istantanee vs valutazione manuale\n",
    "- **üéØ Consistenza**: Eliminazione della variabilit√† umana\n",
    "- **üìà Scalabilit√†**: Gestione di migliaia di combinazioni\n",
    "- **üîÑ Adattabilit√†**: Aggiornamento continuo con nuovi dati\n",
    "- **üìä Quantificazione**: Scores numerici e confidence metrics\n",
    "\n",
    "### üõ†Ô∏è Estensioni Future\n",
    "\n",
    "- **üåê API REST**: Integrazione con sistemi esterni\n",
    "- **üì± Web Interface**: Dashboard interattivo\n",
    "- **üîÑ Continuous Learning**: Aggiornamento automatico con feedback\n",
    "- **üéØ Specialized Models**: Modelli specifici per tipi di missione\n",
    "- **ü§ù Integration**: Connessione diretta con il framework CRAALSP\n",
    "\n",
    "---\n",
    "\n",
    "**‚úÖ Il sistema AI per Risk Assessment Spaziale √® ora pronto per l'uso!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d67e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ DEMO FINALE E ISTRUZIONI PER L'USO\n",
    "print(\"üöÄ\" + \"=\"*80 + \"üöÄ\")\n",
    "print(\"    üéØ AI RISK ASSESSMENT SYSTEM FOR SPACE CYBERSECURITY - READY! üéØ\")\n",
    "print(\"üöÄ\" + \"=\"*80 + \"üöÄ\")\n",
    "\n",
    "print(\"\"\"\n",
    "‚ú® SISTEMA COMPLETAMENTE OPERATIVO! ‚ú®\n",
    "\n",
    "üéÆ Per utilizzare l'interfaccia interattiva:\n",
    "   >>> interface.run_interactive_session()\n",
    "\n",
    "ü§ñ Per predizioni dirette:\n",
    "   >>> result = ai_system.predict_risk_assessment(\"threat_name\", \"asset_name\")\n",
    "   >>> print(result)\n",
    "\n",
    "üß™ Per eseguire test rapidi:\n",
    "   >>> interface.run_quick_examples()\n",
    "\n",
    "üìä Per vedere le statistiche:\n",
    "   >>> interface.show_system_stats()\n",
    "\n",
    "üìã Esempi di minacce:\n",
    "   - \"Social Engineering\"\n",
    "   - \"Malicious code / software / activity: Network exploit\"\n",
    "   - \"Man-in-the-Middle (MITM)\"\n",
    "   - \"Supply Chain Compromise\"\n",
    "\n",
    "üè¢ Esempi di asset:\n",
    "   - \"Mission Control Commanding\"\n",
    "   - \"Space Platform Communication\"\n",
    "   - \"Ground Station Reception\"\n",
    "   - \"Link Space Ground Segment\"\n",
    "\n",
    "üéØ FUNZIONALIT√Ä PRINCIPALI:\n",
    "   ‚úÖ Predizione automatica dei 7 criteri di minaccia\n",
    "   ‚úÖ Predizione automatica dei 9 criteri di asset\n",
    "   ‚úÖ Classificazione del livello di rischio finale\n",
    "   ‚úÖ Integrazione con dati reali del framework CRAALSP\n",
    "   ‚úÖ Confidence scores per validare le predizioni\n",
    "   ‚úÖ Contesto arricchito con CVE e controlli applicabili\n",
    "\n",
    "üöÄ Il sistema √® pronto per essere utilizzato nella tua ricerca!\n",
    "\"\"\")\n",
    "\n",
    "# Esegui una demo finale se tutto √® pronto\n",
    "if ai_system.is_trained:\n",
    "    print(\"üé¨ DEMO FINALE - Risk Assessment Automatico:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    demo_cases = [\n",
    "        (\"Social Engineering\", \"Mission Control Commanding\"),\n",
    "        (\"Supply Chain Compromise\", \"Space Platform Communication\")\n",
    "    ]\n",
    "    \n",
    "    for threat, asset in demo_cases:\n",
    "        try:\n",
    "            result = ai_system.predict_risk_assessment(threat, asset)\n",
    "            print(f\"\\\\nüéØ {threat} ‚Üí {asset}\")\n",
    "            print(f\"   üìä Risk Level: {result['risk_level']}\")\n",
    "            print(f\"   üé≤ Confidence: {result['confidence_score']:.1%}\")\n",
    "            print(f\"   ‚ö° Avg Threat Score: {np.mean(list(result['threat_scores'].values())):.2f}/5.0\")\n",
    "            print(f\"   üè¢ Avg Asset Score: {np.mean(list(result['asset_scores'].values())):.2f}/5.0\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Errore: {str(e)}\")\n",
    "    \n",
    "    print(\"\\\\nüéâ Sistema AI Risk Assessment completamente funzionante!\")\n",
    "    print(\"üéì Pronto per essere utilizzato nella tua tesi!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Ricorda di eseguire l'addestramento prima di utilizzare il sistema!\")\n",
    "\n",
    "print(\"\\\\n\" + \"üöÄ\" + \"=\"*80 + \"üöÄ\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
