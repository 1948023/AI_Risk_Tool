{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1948023/AI_Risk_Tool/blob/main/Enhanced_AI_Risk_Assessment_Tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enhanced_risk_tool"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# 🚀 ENHANCED AI Risk Assessment Tool for Space Missions\n",
        "# Versione Migliorata con Accuratezza Aumentata\n",
        "# ====================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, learning_curve\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"🚀 Inizializzazione del Sistema AI Risk Assessment ENHANCED\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ====================================================================\n",
        "# 📊 DEFINIZIONE DEI CRITERI DI RISCHIO\n",
        "# ====================================================================\n",
        "\n",
        "# Criteri per le minacce (7 criteri: 5 likelihood + 2 impact)\n",
        "THREAT_CRITERIA = {\n",
        "    \"vulnerability_effectiveness\": \"Valuta l'efficacia dello sfruttamento delle vulnerabilità\",\n",
        "    \"mitigation_presence\": \"Valuta la presenza di contromisure di sicurezza\",\n",
        "    \"detection_probability\": \"Misura la probabilità di rilevamento delle attività malevole\",\n",
        "    \"access_complexity\": \"Valuta la difficoltà di accesso per un attaccante\",\n",
        "    \"privilege_requirement\": \"Valuta il livello di privilegi necessari\",\n",
        "    \"response_delay\": \"Misura la velocità di risposta agli incidenti\",\n",
        "    \"resilience_impact\": \"Valuta l'impatto sulla resilienza operativa\"\n",
        "}\n",
        "\n",
        "# Criteri per gli asset (9 criteri: 4 likelihood + 5 impact)\n",
        "ASSET_CRITERIA = {\n",
        "    \"dependency\": \"Valuta quanto l'asset sia critico per le operazioni\",\n",
        "    \"penetration\": \"Valuta il livello di accesso ottenibile attraverso questo asset\",\n",
        "    \"cyber_maturity\": \"Valuta la maturità della governance cybersecurity\",\n",
        "    \"trust\": \"Valuta l'affidabilità degli stakeholder coinvolti\",\n",
        "    \"performance\": \"Misura l'impatto sulle prestazioni operative\",\n",
        "    \"schedule\": \"Valuta l'impatto sui tempi di progetto\",\n",
        "    \"costs\": \"Valuta l'impatto finanziario\",\n",
        "    \"reputation\": \"Valuta l'impatto reputazionale\",\n",
        "    \"recovery\": \"Misura tempo ed effort per il ripristino\"\n",
        "}\n",
        "\n",
        "# THREATS AGGIORNATE\n",
        "THREATS = [\n",
        "    \"Abuse of leaked data\",\n",
        "    \"Abuse / Falsification of right\",\n",
        "    \"Compromising confidentail information (data breaches): Exfiltration\",\n",
        "    \"Denial of Service (DoS)\",\n",
        "    \"Data modification\",\n",
        "    \"Electromagnetic interference\",\n",
        "    \"Firmware corruption\",\n",
        "    \"Identity Theft\",\n",
        "    \"Jamming\",\n",
        "    \"Malicious code/ software/activity: Cryptographic exploit\",\n",
        "    \"Malicious code/ software/activity: Malicious injection\",\n",
        "    \"Malicious code/ software/activity: Network exploit\",\n",
        "    \"Malicious code/ software/activity: Software and vulnerabilities' exploit\",\n",
        "    \"Manipulation of hardware and software: Zero Day exploit\",\n",
        "    \"Preventing services\",\n",
        "    \"Resource exhaustion\",\n",
        "    \"Seizure of control: Satellite bus\",\n",
        "    \"Social Engineering\",\n",
        "    \"Spoofing\",\n",
        "    \"Supply Chain Compromise\",\n",
        "    \"Theft of authentication information\",\n",
        "    \"Unauthorized modification: Parameters\",\n",
        "    \"Unauthorized use of equipment\",\n",
        "    \"Hijacking\",\n",
        "    \"Interception of communication\",\n",
        "    \"Man-in-the-Middle (MITM)\",\n",
        "    \"Network manipulation (Bus-Payload Link)\",\n",
        "    \"Network traffic manipulation (TC)\",\n",
        "    \"Position detection (telemetry)\",\n",
        "    \"Replay of recorded authentic communication traffic\",\n",
        "    \"Unauthorized access\",\n",
        "    \"Coercion, extortion or corruption\",\n",
        "    \"Damage/ Destruction of segment assets\",\n",
        "    \"Damage/ Destruction of the satellite via the use of ASAT / Proximity operations\",\n",
        "    \"Loss during shipping\",\n",
        "    \"Sabotage through hardware/software\",\n",
        "    \"Unauthorized physical access\",\n",
        "    \"Lack of Segregation\",\n",
        "    \"Operating errors\",\n",
        "    \"Software misconfiguration\",\n",
        "    \"Inadequate security planning / management\",\n",
        "    \"Failure of air conditioning or water supply\",\n",
        "    \"Failure of Cloud infrastructure\",\n",
        "    \"Failure of communication networks\",\n",
        "    \"Failure of power supply\",\n",
        "    \"Rogue hardware\",\n",
        "    \"Personnel Absence\",\n",
        "    \"Security services failure\",\n",
        "    \"Atmospheric hazards\",\n",
        "    \"Environmental hazards\",\n",
        "    \"Data leaks\",\n",
        "    \"Misuse of equipment\",\n",
        "    \"Negligence of asset handling security requirements\",\n",
        "    \"Refusal of actions\",\n",
        "    \"Third Party non compliance (supply chain)\",\n",
        "    \"Unauthorized access to recycled or disposed media\",\n",
        "    \"Failure to maintain information systems\",\n",
        "    \"Legacy Software\"\n",
        "]\n",
        "\n",
        "# ASSET CATEGORIES AGGIORNATE\n",
        "ASSET_CATEGORIES = [\n",
        "    \"Ground_Station_Tracking\", \"Ground_Station_Ranging\", \"Ground_Station_Transmission\", \"Ground_Station_Reception\",\n",
        "    \"Mission_Control_Telemetry_Processing\", \"Mission_Control_Commanding\", \"Mission_Control_Analysis_Support\",\n",
        "    \"Data_Processing_Mission_Analysis\", \"Data_Processing_Payload_Processing\",\n",
        "    \"Remote_Terminals_Network_Access\", \"Remote_Terminals_Software_Access\",\n",
        "    \"User_Ground_Segment_Development\", \"User_Ground_Segment_Supportive\", \"User_Ground_Segment_Operations\",\n",
        "    \"Space_Platform_Electrical_Power\", \"Space_Platform_Attitude_Control\", \"Space_Platform_Communication\",\n",
        "    \"Space_Platform_Command_Data_Handling\", \"Space_Platform_Telemetry\", \"Space_Platform_Tracking\",\n",
        "    \"Space_Payload_Data_Handling_Systems\", \"Space_Payload_Communication_Module\", \"Space_Payload_Untrusted_Data_Handling\",\n",
        "    \"Link_Platform_Payload\", \"Link_Ground_Segment_Components\", \"Link_Two_Space_Systems\", \"Link_Two_Ground_WANs\",\n",
        "    \"Link_Space_Ground_Segment\", \"Link_Space_User_Segment\", \"Link_Ground_User_Segment\", \"Link_Two_Users\",\n",
        "    \"User_Transmission\", \"User_Reception\", \"User_Processing\"\n",
        "]\n",
        "\n",
        "print(\"✅ Criteri di rischio definiti\")\n",
        "print(f\"📊 Criteri minacce: {len(THREAT_CRITERIA)}\")\n",
        "print(f\"📊 Criteri asset: {len(ASSET_CRITERIA)}\")\n",
        "print(f\"📊 Threats: {len(THREATS)}\")\n",
        "print(f\"📊 Asset Categories: {len(ASSET_CATEGORIES)}\")\n",
        "\n",
        "# ====================================================================\n",
        "# 🧠 EXPERT-BASED SCORING SYSTEM\n",
        "# ====================================================================\n",
        "\n",
        "class ExpertScoringSystem:\n",
        "    def __init__(self):\n",
        "        # Matrice di correlazione threat-asset basata su conoscenza esperta\n",
        "        self.threat_asset_correlations = {\n",
        "            'space_platform': {\n",
        "                'jamming': 4.5, 'electromagnetic_interference': 4.8, 'asat': 5.0,\n",
        "                'firmware_corruption': 4.2, 'unauthorized_modification': 4.0\n",
        "            },\n",
        "            'mission_control': {\n",
        "                'unauthorized_access': 4.5, 'malicious_code': 4.3, 'social_engineering': 4.0,\n",
        "                'supply_chain_compromise': 4.2, 'insider_threat': 3.8\n",
        "            },\n",
        "            'ground_station': {\n",
        "                'physical_attack': 4.0, 'jamming': 4.2, 'spoofing': 3.8,\n",
        "                'equipment_failure': 3.5\n",
        "            },\n",
        "            'communication_link': {\n",
        "                'mitm': 4.3, 'interception': 4.5, 'replay': 3.9,\n",
        "                'jamming': 4.0, 'spoofing': 4.2\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        # Pesi per diversi tipi di threat\n",
        "        self.threat_type_weights = {\n",
        "            'destructive': {'impact_multiplier': 1.3, 'likelihood_multiplier': 0.8},\n",
        "            'cyber': {'impact_multiplier': 1.1, 'likelihood_multiplier': 1.2},\n",
        "            'human': {'impact_multiplier': 0.9, 'likelihood_multiplier': 1.1},\n",
        "            'environmental': {'impact_multiplier': 1.0, 'likelihood_multiplier': 0.7}\n",
        "        }\n",
        "        \n",
        "        # Pesi per diversi tipi di asset\n",
        "        self.asset_type_weights = {\n",
        "            'space': {'criticality_multiplier': 1.4, 'recovery_multiplier': 1.5},\n",
        "            'mission_control': {'criticality_multiplier': 1.3, 'recovery_multiplier': 1.2},\n",
        "            'ground': {'criticality_multiplier': 1.1, 'recovery_multiplier': 1.0},\n",
        "            'user': {'criticality_multiplier': 0.8, 'recovery_multiplier': 0.9}\n",
        "        }\n",
        "\n",
        "    def classify_threat(self, threat):\n",
        "        \"\"\"Classifica il tipo di threat\"\"\"\n",
        "        threat_lower = threat.lower()\n",
        "        \n",
        "        if any(keyword in threat_lower for keyword in ['destruction', 'damage', 'asat', 'sabotage']):\n",
        "            return 'destructive'\n",
        "        elif any(keyword in threat_lower for keyword in ['malicious', 'exploit', 'injection', 'mitm', 'dos']):\n",
        "            return 'cyber'\n",
        "        elif any(keyword in threat_lower for keyword in ['social', 'coercion', 'negligence', 'error']):\n",
        "            return 'human'\n",
        "        elif any(keyword in threat_lower for keyword in ['failure', 'atmospheric', 'hazards']):\n",
        "            return 'environmental'\n",
        "        else:\n",
        "            return 'cyber'  # default\n",
        "\n",
        "    def classify_asset(self, asset):\n",
        "        \"\"\"Classifica il tipo di asset\"\"\"\n",
        "        asset_lower = asset.lower()\n",
        "        \n",
        "        if 'space_platform' in asset_lower or 'space_payload' in asset_lower:\n",
        "            return 'space'\n",
        "        elif 'mission_control' in asset_lower:\n",
        "            return 'mission_control'\n",
        "        elif 'ground_station' in asset_lower or 'data_processing' in asset_lower:\n",
        "            return 'ground'\n",
        "        elif 'user' in asset_lower or 'remote_terminals' in asset_lower:\n",
        "            return 'user'\n",
        "        else:\n",
        "            return 'ground'  # default\n",
        "\n",
        "    def calculate_base_correlation(self, threat, asset):\n",
        "        \"\"\"Calcola correlazione base threat-asset\"\"\"\n",
        "        threat_type = self.classify_threat(threat)\n",
        "        asset_type = self.classify_asset(asset)\n",
        "        \n",
        "        # Matrice di correlazione base\n",
        "        correlation_matrix = {\n",
        "            ('destructive', 'space'): 4.5,\n",
        "            ('destructive', 'mission_control'): 3.2,\n",
        "            ('destructive', 'ground'): 3.8,\n",
        "            ('destructive', 'user'): 2.5,\n",
        "            ('cyber', 'space'): 3.8,\n",
        "            ('cyber', 'mission_control'): 4.3,\n",
        "            ('cyber', 'ground'): 3.9,\n",
        "            ('cyber', 'user'): 3.5,\n",
        "            ('human', 'space'): 2.8,\n",
        "            ('human', 'mission_control'): 3.8,\n",
        "            ('human', 'ground'): 3.5,\n",
        "            ('human', 'user'): 3.2,\n",
        "            ('environmental', 'space'): 3.5,\n",
        "            ('environmental', 'mission_control'): 2.8,\n",
        "            ('environmental', 'ground'): 3.2,\n",
        "            ('environmental', 'user'): 2.5\n",
        "        }\n",
        "        \n",
        "        return correlation_matrix.get((threat_type, asset_type), 3.0)\n",
        "\n",
        "    def generate_expert_scores(self, threat, asset):\n",
        "        \"\"\"Genera score basati su conoscenza esperta\"\"\"\n",
        "        base_correlation = self.calculate_base_correlation(threat, asset)\n",
        "        threat_type = self.classify_threat(threat)\n",
        "        asset_type = self.classify_asset(asset)\n",
        "        \n",
        "        threat_scores = {}\n",
        "        asset_scores = {}\n",
        "        \n",
        "        # Calcola threat scores\n",
        "        for criterion in THREAT_CRITERIA.keys():\n",
        "            if criterion in ['vulnerability_effectiveness', 'mitigation_presence', 'detection_probability', \n",
        "                           'access_complexity', 'privilege_requirement']:  # likelihood criteria\n",
        "                base_score = base_correlation * 0.8\n",
        "                if threat_type in self.threat_type_weights:\n",
        "                    base_score *= self.threat_type_weights[threat_type]['likelihood_multiplier']\n",
        "            else:  # impact criteria\n",
        "                base_score = base_correlation * 0.9\n",
        "                if threat_type in self.threat_type_weights:\n",
        "                    base_score *= self.threat_type_weights[threat_type]['impact_multiplier']\n",
        "            \n",
        "            # Aggiungi variabilità controllata\n",
        "            noise = np.random.normal(0, 0.3)\n",
        "            final_score = max(1, min(5, base_score + noise))\n",
        "            threat_scores[f\"threat_{criterion}\"] = final_score\n",
        "        \n",
        "        # Calcola asset scores\n",
        "        for criterion in ASSET_CRITERIA.keys():\n",
        "            if criterion in ['dependency', 'penetration', 'cyber_maturity', 'trust']:  # likelihood criteria\n",
        "                base_score = base_correlation * 0.85\n",
        "            else:  # impact criteria\n",
        "                base_score = base_correlation * 0.9\n",
        "                if asset_type in self.asset_type_weights:\n",
        "                    base_score *= self.asset_type_weights[asset_type]['criticality_multiplier']\n",
        "            \n",
        "            # Aggiungi variabilità controllata\n",
        "            noise = np.random.normal(0, 0.25)\n",
        "            final_score = max(1, min(5, base_score + noise))\n",
        "            asset_scores[f\"asset_{criterion}\"] = final_score\n",
        "        \n",
        "        return threat_scores, asset_scores\n",
        "\n",
        "# ====================================================================\n",
        "# 🎯 ENHANCED DATASET GENERATION\n",
        "# ====================================================================\n",
        "\n",
        "def generate_enhanced_dataset(n_samples=50000):  # Aumentato da 1M per velocità\n",
        "    \"\"\"\n",
        "    Genera un dataset migliorato con scoring basato su expertise\n",
        "    \"\"\"\n",
        "    print(f\"🏗️ Generazione dataset enhanced con {n_samples} campioni...\")\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    expert_system = ExpertScoringSystem()\n",
        "    \n",
        "    data = []\n",
        "    \n",
        "    for i in range(n_samples):\n",
        "        if i % 10000 == 0:\n",
        "            print(f\"  Progresso: {i}/{n_samples} ({i/n_samples*100:.1f}%)\")\n",
        "        \n",
        "        # Selezione threat e asset\n",
        "        threat = np.random.choice(THREATS)\n",
        "        asset = np.random.choice(ASSET_CATEGORIES)\n",
        "        \n",
        "        # Genera score usando sistema esperto\n",
        "        threat_scores, asset_scores = expert_system.generate_expert_scores(threat, asset)\n",
        "        \n",
        "        # Calcolo likelihood e impact\n",
        "        threat_likelihood_values = [threat_scores[f\"threat_{k}\"] for k in list(THREAT_CRITERIA.keys())[:5]]\n",
        "        threat_impact_values = [threat_scores[f\"threat_{k}\"] for k in list(THREAT_CRITERIA.keys())[5:]]\n",
        "        \n",
        "        asset_likelihood_values = [asset_scores[f\"asset_{k}\"] for k in list(ASSET_CRITERIA.keys())[:4]]\n",
        "        asset_impact_values = [asset_scores[f\"asset_{k}\"] for k in list(ASSET_CRITERIA.keys())[4:]]\n",
        "        \n",
        "        # Media pesata invece di media quadratica\n",
        "        combined_likelihood = (np.mean(threat_likelihood_values) * 0.6 + np.mean(asset_likelihood_values) * 0.4)\n",
        "        combined_impact = (np.mean(threat_impact_values) * 0.7 + np.mean(asset_impact_values) * 0.3)\n",
        "        \n",
        "        # Categorie\n",
        "        def score_to_category(score):\n",
        "            if score <= 2:\n",
        "                return \"Low\"\n",
        "            elif score <= 3:\n",
        "                return \"Medium\"\n",
        "            elif score <= 4:\n",
        "                return \"High\"\n",
        "            else:\n",
        "                return \"Very High\"\n",
        "        \n",
        "        likelihood_cat = score_to_category(combined_likelihood)\n",
        "        impact_cat = score_to_category(combined_impact)\n",
        "        \n",
        "        # Calcolo rischio con formula migliorata\n",
        "        risk_score = np.sqrt(combined_likelihood * combined_impact)  # Media geometrica\n",
        "        risk_cat = score_to_category(risk_score)\n",
        "        \n",
        "        # Record con feature aggiuntive\n",
        "        record = {\n",
        "            'threat': threat,\n",
        "            'asset_category': asset,\n",
        "            'threat_type': expert_system.classify_threat(threat),\n",
        "            'asset_type': expert_system.classify_asset(asset),\n",
        "            'combined_likelihood': combined_likelihood,\n",
        "            'combined_impact': combined_impact,\n",
        "            'risk_score': risk_score,\n",
        "            'likelihood_category': likelihood_cat,\n",
        "            'impact_category': impact_cat,\n",
        "            'risk_category': risk_cat,\n",
        "            **threat_scores,\n",
        "            **asset_scores\n",
        "        }\n",
        "        \n",
        "        data.append(record)\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    print(f\"✅ Dataset enhanced generato: {len(df)} campioni\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "# ====================================================================\n",
        "# 🔧 ADVANCED FEATURE ENGINEERING\n",
        "# ====================================================================\n",
        "\n",
        "class AdvancedFeatureEngineer:\n",
        "    def __init__(self):\n",
        "        self.label_encoders = {}\n",
        "        self.scaler = StandardScaler()\n",
        "    \n",
        "    def create_advanced_features(self, df):\n",
        "        \"\"\"Crea feature avanzate per migliorare le predizioni\"\"\"\n",
        "        print(\"🔧 Creazione feature avanzate...\")\n",
        "        \n",
        "        df_enhanced = df.copy()\n",
        "        \n",
        "        # Feature di interazione\n",
        "        threat_cols = [col for col in df.columns if col.startswith('threat_')]\n",
        "        asset_cols = [col for col in df.columns if col.startswith('asset_')]\n",
        "        \n",
        "        # Statistiche aggregate\n",
        "        df_enhanced['threat_score_mean'] = df[threat_cols].mean(axis=1)\n",
        "        df_enhanced['threat_score_max'] = df[threat_cols].max(axis=1)\n",
        "        df_enhanced['threat_score_std'] = df[threat_cols].std(axis=1)\n",
        "        \n",
        "        df_enhanced['asset_score_mean'] = df[asset_cols].mean(axis=1)\n",
        "        df_enhanced['asset_score_max'] = df[asset_cols].max(axis=1)\n",
        "        df_enhanced['asset_score_std'] = df[asset_cols].std(axis=1)\n",
        "        \n",
        "        # Feature di ratio\n",
        "        df_enhanced['threat_asset_ratio'] = df_enhanced['threat_score_mean'] / (df_enhanced['asset_score_mean'] + 0.001)\n",
        "        df_enhanced['likelihood_impact_ratio'] = df_enhanced['combined_likelihood'] / (df_enhanced['combined_impact'] + 0.001)\n",
        "        \n",
        "        # Feature di correlazione\n",
        "        df_enhanced['threat_likelihood_subset'] = df[['threat_vulnerability_effectiveness', \n",
        "                                                     'threat_mitigation_presence', \n",
        "                                                     'threat_detection_probability']].mean(axis=1)\n",
        "        \n",
        "        df_enhanced['asset_impact_subset'] = df[['asset_performance', \n",
        "                                                'asset_costs', \n",
        "                                                'asset_recovery']].mean(axis=1)\n",
        "        \n",
        "        # Encode categorical features\n",
        "        categorical_features = ['threat', 'asset_category', 'threat_type', 'asset_type']\n",
        "        \n",
        "        for feature in categorical_features:\n",
        "            if feature not in self.label_encoders:\n",
        "                self.label_encoders[feature] = LabelEncoder()\n",
        "            \n",
        "            df_enhanced[f'{feature}_encoded'] = self.label_encoders[feature].fit_transform(df_enhanced[feature])\n",
        "        \n",
        "        print(f\"✅ Feature create: {df_enhanced.shape[1]} colonne totali\")\n",
        "        return df_enhanced\n",
        "    \n",
        "    def prepare_features_and_targets(self, df):\n",
        "        \"\"\"Prepara features e targets per l'addestramento\"\"\"\n",
        "        # Features numeriche\n",
        "        numeric_features = [\n",
        "            'threat_encoded', 'asset_category_encoded', 'threat_type_encoded', 'asset_type_encoded',\n",
        "            'threat_score_mean', 'threat_score_max', 'threat_score_std',\n",
        "            'asset_score_mean', 'asset_score_max', 'asset_score_std',\n",
        "            'threat_asset_ratio', 'likelihood_impact_ratio',\n",
        "            'threat_likelihood_subset', 'asset_impact_subset'\n",
        "        ]\n",
        "        \n",
        "        # Aggiungi tutti i criteri individuali\n",
        "        threat_criteria_cols = [f\"threat_{k}\" for k in THREAT_CRITERIA.keys()]\n",
        "        asset_criteria_cols = [f\"asset_{k}\" for k in ASSET_CRITERIA.keys()]\n",
        "        \n",
        "        X_features = numeric_features + threat_criteria_cols + asset_criteria_cols\n",
        "        X = df[X_features].values\n",
        "        \n",
        "        # Targets\n",
        "        y_likelihood = df['combined_likelihood'].values\n",
        "        y_impact = df['combined_impact'].values\n",
        "        y_risk = df['risk_score'].values\n",
        "        \n",
        "        return X, y_likelihood, y_impact, y_risk, X_features\n",
        "\n",
        "# ====================================================================\n",
        "# 🤖 ENHANCED AI MODEL SYSTEM\n",
        "# ====================================================================\n",
        "\n",
        "class EnhancedAIRiskSystem:\n",
        "    def __init__(self):\n",
        "        # Modelli multipli per ensemble\n",
        "        self.models = {\n",
        "            'random_forest': RandomForestRegressor(\n",
        "                n_estimators=200,\n",
        "                max_depth=20,\n",
        "                min_samples_split=3,\n",
        "                min_samples_leaf=2,\n",
        "                random_state=42,\n",
        "                n_jobs=-1\n",
        "            ),\n",
        "            'gradient_boosting': GradientBoostingRegressor(\n",
        "                n_estimators=150,\n",
        "                learning_rate=0.1,\n",
        "                max_depth=8,\n",
        "                subsample=0.8,\n",
        "                random_state=42\n",
        "            ),\n",
        "            'neural_network': MLPRegressor(\n",
        "                hidden_layer_sizes=(100, 50, 25),\n",
        "                activation='relu',\n",
        "                alpha=0.001,\n",
        "                learning_rate='adaptive',\n",
        "                max_iter=1000,\n",
        "                random_state=42\n",
        "            )\n",
        "        }\n",
        "        \n",
        "        self.best_model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.is_trained = False\n",
        "        self.feature_names = None\n",
        "    \n",
        "    def train_and_select_best_model(self, X_train, y_train, X_val, y_val):\n",
        "        \"\"\"Addestra tutti i modelli e seleziona il migliore\"\"\"\n",
        "        print(\"🏋️ Addestramento e selezione del miglior modello...\")\n",
        "        \n",
        "        # Normalizza features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_val_scaled = self.scaler.transform(X_val)\n",
        "        \n",
        "        best_score = float('-inf')\n",
        "        \n",
        "        for name, model in self.models.items():\n",
        "            print(f\"  📊 Addestramento {name}...\")\n",
        "            \n",
        "            # Addestramento\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            \n",
        "            # Valutazione\n",
        "            val_pred = model.predict(X_val_scaled)\n",
        "            score = r2_score(y_val, val_pred)\n",
        "            mae = mean_absolute_error(y_val, val_pred)\n",
        "            \n",
        "            print(f\"    R²: {score:.4f}, MAE: {mae:.4f}\")\n",
        "            \n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                self.best_model = model\n",
        "                best_model_name = name\n",
        "        \n",
        "        print(f\"✅ Miglior modello: {best_model_name} (R²: {best_score:.4f})\")\n",
        "        self.is_trained = True\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"Predice usando il miglior modello\"\"\"\n",
        "        if not self.is_trained:\n",
        "            raise ValueError(\"Modello non ancora addestrato!\")\n",
        "        \n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        prediction = self.best_model.predict(X_scaled)\n",
        "        \n",
        "        return np.clip(prediction, 1, 5)\n",
        "    \n",
        "    def evaluate(self, X_test, y_test):\n",
        "        \"\"\"Valuta le performance del modello\"\"\"\n",
        "        predictions = self.predict(X_test)\n",
        "        \n",
        "        metrics = {\n",
        "            'mae': mean_absolute_error(y_test, predictions),\n",
        "            'mse': mean_squared_error(y_test, predictions),\n",
        "            'r2': r2_score(y_test, predictions)\n",
        "        }\n",
        "        \n",
        "        return metrics, predictions\n",
        "\n",
        "# ====================================================================\n",
        "# 🚀 PIPELINE DI ADDESTRAMENTO ENHANCED\n",
        "# ====================================================================\n",
        "\n",
        "print(\"\\n🏗️ GENERAZIONE DATASET ENHANCED\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Genera dataset\n",
        "enhanced_dataset = generate_enhanced_dataset(50000)\n",
        "\n",
        "print(\"\\n🔧 FEATURE ENGINEERING\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Feature engineering\n",
        "feature_engineer = AdvancedFeatureEngineer()\n",
        "enhanced_dataset = feature_engineer.create_advanced_features(enhanced_dataset)\n",
        "\n",
        "# Prepara features e targets\n",
        "X, y_likelihood, y_impact, y_risk, feature_names = feature_engineer.prepare_features_and_targets(enhanced_dataset)\n",
        "\n",
        "print(f\"✅ Features shape: {X.shape}\")\n",
        "print(f\"✅ Numero di features: {len(feature_names)}\")\n",
        "\n",
        "print(\"\\n🏋️ ADDESTRAMENTO MODELLI\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Divisione train/validation/test\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y_risk, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
        "\n",
        "print(f\"📊 Training set: {X_train.shape[0]} campioni\")\n",
        "print(f\"📊 Validation set: {X_val.shape[0]} campioni\")\n",
        "print(f\"📊 Test set: {X_test.shape[0]} campioni\")\n",
        "\n",
        "# Addestra il sistema\n",
        "enhanced_ai_system = EnhancedAIRiskSystem()\n",
        "enhanced_ai_system.feature_names = feature_names\n",
        "enhanced_ai_system.train_and_select_best_model(X_train, y_train, X_val, y_val)\n",
        "\n",
        "print(\"\\n📊 VALUTAZIONE PERFORMANCE\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Valuta il modello\n",
        "test_metrics, test_predictions = enhanced_ai_system.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"🎯 RISULTATI ENHANCED MODEL:\")\n",
        "print(f\"  MAE: {test_metrics['mae']:.4f}\")\n",
        "print(f\"  MSE: {test_metrics['mse']:.4f}\")\n",
        "print(f\"  R²: {test_metrics['r2']:.4f}\")\n",
        "print(f\"  Accuratezza: {test_metrics['r2']:.4f}\")\n",
        "print(f\"  Errore medio: {test_metrics['mae']:.4f}\")\n",
        "\n",
        "# ====================================================================\n",
        "# 🧪 ENHANCED PREDICTION SYSTEM\n",
        "# ====================================================================\n",
        "\n",
        "def enhanced_automated_risk_assessment(threat_name, asset_name, ai_system, feature_engineer, dataset_sample):\n",
        "    \"\"\"\n",
        "    Sistema di valutazione automatica enhanced\n",
        "    \"\"\"\n",
        "    print(f\"\\n🔍 VALUTAZIONE AUTOMATICA ENHANCED\")\n",
        "    print(f\"🎯 Minaccia: {threat_name}\")\n",
        "    print(f\"🏗️ Asset: {asset_name}\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    # Crea un record sintetico per la predizione\n",
        "    expert_system = ExpertScoringSystem()\n",
        "    threat_scores, asset_scores = expert_system.generate_expert_scores(threat_name, asset_name)\n",
        "    \n",
        "    # Calcola likelihood e impact\n",
        "    threat_likelihood_values = [threat_scores[f\"threat_{k}\"] for k in list(THREAT_CRITERIA.keys())[:5]]\n",
        "    threat_impact_values = [threat_scores[f\"threat_{k}\"] for k in list(THREAT_CRITERIA.keys())[5:]]\n",
        "    asset_likelihood_values = [asset_scores[f\"asset_{k}\"] for k in list(ASSET_CRITERIA.keys())[:4]]\n",
        "    asset_impact_values = [asset_scores[f\"asset_{k}\"] for k in list(ASSET_CRITERIA.keys())[4:]]\n",
        "    \n",
        "    combined_likelihood = (np.mean(threat_likelihood_values) * 0.6 + np.mean(asset_likelihood_values) * 0.4)\n",
        "    combined_impact = (np.mean(threat_impact_values) * 0.7 + np.mean(asset_impact_values) * 0.3)\n",
        "    \n",
        "    # Crea record per predizione\n",
        "    prediction_record = {\n",
        "        'threat': threat_name,\n",
        "        'asset_category': asset_name,\n",
        "        'threat_type': expert_system.classify_threat(threat_name),\n",
        "        'asset_type': expert_system.classify_asset(asset_name),\n",
        "        'combined_likelihood': combined_likelihood,\n",
        "        'combined_impact': combined_impact,\n",
        "        'risk_score': np.sqrt(combined_likelihood * combined_impact),\n",
        "        **threat_scores,\n",
        "        **asset_scores\n",
        "    }\n",
        "    \n",
        "    # Converti in DataFrame e applica feature engineering\n",
        "    pred_df = pd.DataFrame([prediction_record])\n",
        "    pred_df_enhanced = feature_engineer.create_advanced_features(pred_df)\n",
        "    \n",
        "    # Estrai features per predizione\n",
        "    X_pred = pred_df_enhanced[ai_system.feature_names].values\n",
        "    \n",
        "    # Predizione\n",
        "    risk_prediction = ai_system.predict(X_pred)[0]\n",
        "    \n",
        "    # Categorie\n",
        "    def score_to_category(score):\n",
        "        if score <= 2:\n",
        "            return \"Low\"\n",
        "        elif score <= 3:\n",
        "            return \"Medium\"\n",
        "        elif score <= 4:\n",
        "            return \"High\"\n",
        "        else:\n",
        "            return \"Very High\"\n",
        "    \n",
        "    likelihood_cat = score_to_category(combined_likelihood)\n",
        "    impact_cat = score_to_category(combined_impact)\n",
        "    risk_cat = score_to_category(risk_prediction)\n",
        "    \n",
        "    # Output risultati\n",
        "    print(f\"📈 Likelihood: {combined_likelihood:.3f} ({likelihood_cat})\")\n",
        "    print(f\"📈 Impact: {combined_impact:.3f} ({impact_cat})\")\n",
        "    print(f\"⚠️ Livello di Rischio AI: {risk_prediction:.3f} ({risk_cat})\")\n",
        "    print(f\"🤖 Confidence Score: {min(test_metrics['r2'] * 100, 95):.1f}%\")\n",
        "    \n",
        "    return {\n",
        "        'threat': threat_name,\n",
        "        'asset': asset_name,\n",
        "        'likelihood': combined_likelihood,\n",
        "        'impact': combined_impact,\n",
        "        'risk_score': risk_prediction,\n",
        "        'risk_category': risk_cat,\n",
        "        'confidence': min(test_metrics['r2'] * 100, 95)\n",
        "    }\n",
        "\n",
        "# ====================================================================\n",
        "# 🧪 TEST ENHANCED SYSTEM\n",
        "# ====================================================================\n",
        "\n",
        "print(\"\\n🧪 TEST SISTEMA ENHANCED\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test con scenari diversi\n",
        "enhanced_test_scenarios = [\n",
        "    (\"Damage/ Destruction of the satellite via the use of ASAT / Proximity operations\", \"Space_Platform_Communication\"),\n",
        "    (\"Malicious code/ software/activity: Network exploit\", \"Mission_Control_Commanding\"),\n",
        "    (\"Jamming\", \"Ground_Station_Tracking\"),\n",
        "    (\"Supply Chain Compromise\", \"Space_Payload_Data_Handling_Systems\"),\n",
        "    (\"Social Engineering\", \"Remote_Terminals_Network_Access\")\n",
        "]\n",
        "\n",
        "enhanced_results = []\n",
        "for threat, asset in enhanced_test_scenarios:\n",
        "    result = enhanced_automated_risk_assessment(threat, asset, enhanced_ai_system, feature_engineer, enhanced_dataset)\n",
        "    enhanced_results.append(result)\n",
        "\n",
        "# ====================================================================\n",
        "# 📈 VISUALIZZAZIONE ENHANCED\n",
        "# ====================================================================\n",
        "\n",
        "print(\"\\n📈 VISUALIZZAZIONE RISULTATI ENHANCED\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Grafico comparativo\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Grafico 1: Performance del modello\n",
        "metrics_names = ['MAE', 'MSE', 'R²']\n",
        "metrics_values = [test_metrics['mae'], test_metrics['mse'], test_metrics['r2']]\n",
        "\n",
        "axes[0,0].bar(metrics_names, metrics_values, color=['lightcoral', 'lightblue', 'lightgreen'])\n",
        "axes[0,0].set_title('Performance Metriche Enhanced Model')\n",
        "axes[0,0].set_ylabel('Score')\n",
        "\n",
        "# Grafico 2: Distribuzione predizioni vs reali\n",
        "axes[0,1].scatter(y_test[:1000], test_predictions[:1000], alpha=0.5)\n",
        "axes[0,1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "axes[0,1].set_xlabel('Valori Reali')\n",
        "axes[0,1].set_ylabel('Predizioni')\n",
        "axes[0,1].set_title('Predizioni vs Valori Reali')\n",
        "\n",
        "# Grafico 3: Risultati test scenari\n",
        "test_names = [f\"{r['threat'][:15]}...\\n{r['asset'][:15]}...\" for r in enhanced_results]\n",
        "risk_scores_enhanced = [r['risk_score'] for r in enhanced_results]\n",
        "confidence_scores = [r['confidence'] for r in enhanced_results]\n",
        "\n",
        "x = np.arange(len(test_names))\n",
        "width = 0.35\n",
        "\n",
        "axes[1,0].bar(x - width/2, risk_scores_enhanced, width, label='Risk Score', color='red', alpha=0.7)\n",
        "axes[1,0].bar(x + width/2, [c/20 for c in confidence_scores], width, label='Confidence/20', color='blue', alpha=0.7)\n",
        "axes[1,0].set_title('Risultati Test Enhanced')\n",
        "axes[1,0].set_ylabel('Score')\n",
        "axes[1,0].set_xticks(x)\n",
        "axes[1,0].set_xticklabels(test_names, rotation=45, ha='right')\n",
        "axes[1,0].legend()\n",
        "\n",
        "# Grafico 4: Feature importance (se disponibile)\n",
        "if hasattr(enhanced_ai_system.best_model, 'feature_importances_'):\n",
        "    importance = enhanced_ai_system.best_model.feature_importances_\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': importance\n",
        "    }).sort_values('importance', ascending=False).head(10)\n",
        "    \n",
        "    axes[1,1].barh(feature_importance_df['feature'], feature_importance_df['importance'])\n",
        "    axes[1,1].set_title('Top 10 Feature Importance')\n",
        "    axes[1,1].set_xlabel('Importance')\n",
        "else:\n",
        "    axes[1,1].text(0.5, 0.5, 'Feature Importance\\nnon disponibile\\nper questo modello', \n",
        "                   ha='center', va='center', transform=axes[1,1].transAxes)\n",
        "    axes[1,1].set_title('Feature Importance')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ====================================================================\n",
        "# 🎉 CONCLUSIONI ENHANCED\n",
        "# ====================================================================\n",
        "\n",
        "print(\"\\n🎉 SISTEMA AI RISK ASSESSMENT ENHANCED COMPLETATO!\")\n",
        "print(\"=\" * 70)\n",
        "print(\"✅ Sistema enhanced addestrato e testato con successo\")\n",
        "print(f\"📊 Accuratezza (R²): {test_metrics['r2']:.4f}\")\n",
        "print(f\"📊 Errore medio (MAE): {test_metrics['mae']:.4f}\")\n",
        "print(f\"📊 Miglioramento accuratezza: +{(test_metrics['r2'] - 0.276):.3f}\")\n",
        "print(f\"📊 Riduzione errore: -{(0.541 - test_metrics['mae']):.3f}\")\n",
        "\n",
        "print(\"\\n🚀 CARATTERISTICHE ENHANCED:\")\n",
        "print(\"  ✅ Expert-based scoring system\")\n",
        "print(\"  ✅ Advanced feature engineering\")\n",
        "print(\"  ✅ Multiple model ensemble\")\n",
        "print(\"  ✅ Improved threat-asset correlations\")\n",
        "print(\"  ✅ Enhanced prediction confidence\")\n",
        "\n",
        "print(\"\\n📝 Per utilizzare il sistema enhanced:\")\n",
        "print(\"   result = enhanced_automated_risk_assessment('threat_name', 'asset_name', enhanced_ai_system, feature_engineer, enhanced_dataset)\")\n",
        "\n",
        "# Salvataggio del modello (opzionale)\n",
        "def save_enhanced_system():\n",
        "    \"\"\"Salva il sistema enhanced\"\"\"\n",
        "    try:\n",
        "        import joblib\n",
        "        joblib.dump({\n",
        "            'ai_system': enhanced_ai_system,\n",
        "            'feature_engineer': feature_engineer,\n",
        "            'test_metrics': test_metrics,\n",
        "            'dataset_sample': enhanced_dataset.head(100)  # Solo un campione\n",
        "        }, 'enhanced_risk_assessment_system.pkl')\n",
        "        print(\"✅ Sistema enhanced salvato!\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Errore nel salvataggio: {e}\")\n",
        "\n",
        "# save_enhanced_system()  # Decommentare per salvare"
      ]
    }
  ]
}